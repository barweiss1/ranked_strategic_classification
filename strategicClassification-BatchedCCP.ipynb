{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranked Strategic Classification ðŸ¦š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our project we tackle the problem of Stategic classification with user dependant responses. \n",
    "\n",
    "We introduce user dependance through competition on $k$ available spots which are given to the top-k rated users.\n",
    "\n",
    "This problem appears in our daily life in multiple places such as acceptance into universities and job interviews, where the users compete for a few available spots.\n",
    "\n",
    "These users are strategic, and can improve their ranking by changing their features. In the example of job interview, can for example create a specialized CV which they know will help them in getting into the job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Notations\n",
    "- Time is assumed to be discrete and denoted by $t\\in\\{0,1,...\\}$\n",
    "- Each user $i$ has initial features $x_i(0)\\in \\mathbb{R}^d$\n",
    "- Each user $i$ updates his features at each time $t$ with a function $x_i(t) = \\Delta_h(x_i(0))$.\n",
    "  \n",
    "<ins>Note:</ins> For simplification, the user always updates his features based on his features at $t=0$.\n",
    "- The set of user features at time $t$ is denoted by $X_t$\n",
    "- Each user has a ground truth rating $r(x_i(0))\\in[0,1]$\n",
    "- We train a model to predict the true ratings $r_{\\theta}(x_i(t))$\n",
    "- Denote the sorted indices of the users based on $r_{\\theta}(x_i(t))$ by $s_i(t) = \\text{argsort}(\\{r_\\theta(x(t))\\}_{x(t)\\in X_t})[i]$\n",
    "\n",
    "Given all of the users and their features, the system predicts the rating for each user, $r_\\theta(x_i(t))$, and accepts the top-$k$ rated users $\\{x_{s_1(t)},...,x_{s_k(t)}\\}$. \n",
    "\n",
    "The users are able to change their features with the following function: $\\Delta_h(x)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We model the environment based on the environment from the paper: *S. Levanon, N. Rosenfeld: \"Strategic Classification Made Practical\", 2021*\n",
    "\n",
    "We assume a behavioral model for the user strategic response $\\Delta_h(\\cdot)$. Given the ratings at time $t$ we calculate 2 thresholds:\n",
    "\n",
    "$$\n",
    "T_{low} = r_\\theta(x_{s_k(t)}(t)), \\quad T_{high} = r_\\theta(x_{s_{k'}(t)}(t)) \n",
    "$$\n",
    "\n",
    "Where $k'< k$ is a positive integer. These thresholds are used to model the behavioral responses. \n",
    "\n",
    "We hypothesize that users will not be satisfied by sitting on the low threshold and will want acceptance confidence at the higher rating threshold. Using this we design the following reward function: \n",
    "\n",
    "$$h(r) = q\\cdot\\sigma^*_{\\tau}\\left(\\frac{r-T_{low}}{\\tau_{low}}\\right) + (1-q)\\cdot\\sigma^*_{\\tau}\\left(\\frac{r-T_{high}}{\\tau_{high}}\\right)$$\n",
    "\n",
    "Where $q\\in[0,1]$, and $\\sigma(\\cdot)$ is a sigmoid function that will be discussed in the CCP section. This gives small reward $q$ for acceptance and the rest is given for passing the higher threshold.\n",
    "\n",
    "The $\\tau$ parameters express the softness of threshold; small $\\tau$ will give a step like reward and large $\\tau$ will give a smoother reward.\n",
    "\n",
    "The user responses are modeled as \n",
    "\n",
    "$$\\Delta_h(x) = \\underset{x'}{\\text{argmax }} h(r_\\theta(x')) - c(x,x')$$\n",
    "\n",
    "Where $c(\\cdot,\\cdot)$ is a convex cost function for feature change, we use euclidean distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T08:45:57.833836100Z",
     "start_time": "2024-05-12T08:45:57.286965300Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "import cvxpy as cp\n",
    "import torch\n",
    "import numpy as np\n",
    "from cvxpylayers.torch import CvxpyLayer\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics import zero_one_loss, confusion_matrix\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.datasets import make_classification\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import os, psutil\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import ndcg_score, precision_score, recall_score, mean_squared_error\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "TRAIN_SLOPE = 1\n",
    "EVAL_SLOPE = 5\n",
    "X_LOWER_BOUND = -10\n",
    "X_UPPER_BOUND = 10\n",
    "SEED = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few useful utilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T08:45:57.866065Z",
     "start_time": "2024-05-12T08:45:57.351100500Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_data(X, Y, percentage):\n",
    "    num_val = int(len(X)*percentage)\n",
    "    return X[num_val:], Y[num_val:], X[:num_val], Y[:num_val]\n",
    "\n",
    "def shuffle(X, Y):\n",
    "    torch.manual_seed(0)\n",
    "    np.random.seed(0)\n",
    "    data = torch.cat((Y, X), 1)\n",
    "    data = data[torch.randperm(data.size()[0])]\n",
    "    X = data[:, 1:]\n",
    "    Y = data[:, 0]\n",
    "    return X, Y\n",
    "\n",
    "def conf_mat(Y1, Y2):\n",
    "    num_of_samples = len(Y1)\n",
    "    mat = confusion_matrix(Y1, Y2, labels=[-1, 1])*100/num_of_samples\n",
    "    acc = np.trace(mat)\n",
    "    return mat, acc\n",
    "\n",
    "def calc_accuracy(Y, Ypred):\n",
    "    num = len(Y)\n",
    "    temp = Y - Ypred\n",
    "    acc = len(temp[temp == 0])*1./num\n",
    "    return acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gain & Cost functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In this section we implement the score functions and based on it, a differientiable sigmoid-like proxy for the sign operation in the $h$ function:\n",
    "\n",
    "$$\\sigma_\\tau^*(z) = 0.5 \\cdot \\sqrt{(\\tau^{-1}(z-T_{low})+1)^2+1} - 0.5 \\cdot \\sqrt{(\\tau^{-1}(z-T_{high})-1)^2+1}$$\n",
    "\n",
    "We denote $0.5 \\cdot \\sqrt{(\\tau^{-1}(z-T_{low})+1)^2+1}$ with $f(x)$ and $0.5 \\cdot \\sqrt{(\\tau^{-1}(z-T_{high})-1)^2+1}$ with $g(x)$.\n",
    "\n",
    "This function can be written as a sum of convex and concave funcitons, a property which is essential to the CCP method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T08:45:57.983837500Z",
     "start_time": "2024-05-12T08:45:57.411953900Z"
    }
   },
   "outputs": [],
   "source": [
    "def score(x, w, b):\n",
    "    return x@w + b\n",
    "\n",
    "def f(x, w, b, slope, T):\n",
    "    return 0.5*cp.norm(cp.hstack([1, (slope*(score(x, w, b)-T) + 1)]), 2)\n",
    "    # return 0.5*cp.sqrt(1+cp.square((slope*(score(x, w, b) - T) + 1)))\n",
    "\n",
    "def g(x, w, b, slope, T):\n",
    "    res = 0.5*cp.norm(cp.hstack([1, (slope*(score(x, w, b) - T) - 1)]), 2)\n",
    "    # score_expr = score(x, w, b)\n",
    "    # score_slope = slope*(score(x, w, b) - T)\n",
    "    # score_vec = cp.hstack([1, (slope*(score(x, w, b) - T) - 1)])\n",
    "    # print('res')\n",
    "    # print(\"Nonnegative? \", res.is_nonneg())\n",
    "    # print(\"Convex? \", res.is_convex())\n",
    "    # print(\"Affine? \", res.is_affine())\n",
    "    # print(\"NonPositive? \", res.is_nonpos())\n",
    "    # print(\"DCP? \", res.is_dcp())\n",
    "    # print('score_expr')\n",
    "    # print(\"Nonnegative? \", score_expr.is_nonneg())\n",
    "    # print(\"Convex? \", score_expr.is_convex())\n",
    "    # print(\"Affine? \", score_expr.is_affine())\n",
    "    # print(\"NonPositive? \", score_expr.is_nonpos())\n",
    "    # print('score_slope')\n",
    "    # print(\"Nonnegative? \", score_vec.is_nonneg())\n",
    "    # print(\"Convex? \", score_slope.is_convex())\n",
    "    # print(\"Affine? \", score_slope.is_affine())\n",
    "    # print(\"NonPositive? \", score_slope.is_nonpos())\n",
    "    # print('score_vec')\n",
    "    # print(\"Nonnegative? \", score_vec.is_nonneg())\n",
    "    # print(\"Convex? \", score_vec.is_convex())\n",
    "    # print(\"Affine? \", score_vec.is_affine())\n",
    "    # print(\"NonPositive? \", score_vec.is_nonpos())\n",
    "    # print(f\"x's shape={x.shape}\")\n",
    "    # print(f\"score's shape={(score(x, w, b)-T).shape}\")\n",
    "    # print(f\"g's shape={cp.hstack([1, (slope*(score(x, w, b)-T) - 1)]).shape}\")\n",
    "    # print(f\"res's shape={res}\")\n",
    "    return res\n",
    "\n",
    "def c(x, r, x_dim, scale):\n",
    "    return (scale)*cp.sum_squares(x-r)\n",
    "\n",
    "def f_derivative(x, w, b, slope, T):\n",
    "    return 0.5*cp.multiply(slope*((slope*(score(x, w, b)-T) + 1)/cp.sqrt((slope*(score(x, w, b)-T) + 1)**2 + 1)), w)\n",
    "\n",
    "def f_batch(x, w, b, slope, T):\n",
    "    return cp.norm(cp.vstack([np.ones(x.shape[0]), slope*(score(x, w, b) - T) + 1]), 2, axis=0)\n",
    "\n",
    "def g_batch(x, w, b, slope, T):\n",
    "    return cp.norm(cp.vstack([np.ones((1, x.shape[0])), cp.reshape((slope*(score(x, w, b)-T) - 1), (1, x.shape[0]))]), 2, axis=0)\n",
    "\n",
    "def c_batch(x, r, x_dim, scale):\n",
    "    return (scale)*cp.square(cp.norm(x-r, 2, axis=1))\n",
    "\n",
    "def f_derivative_batch(x, w, b, slope, T):\n",
    "    nablas = 0.5*slope*((slope*(score(x, w, b) - T) + 1)/cp.sqrt((slope*(score(x, w, b) - T) + 1)**2 + 1))\n",
    "    return cp.reshape(nablas, (nablas.shape[0], 1))@cp.reshape(w, (1, x.shape[1]))\n",
    "\n",
    "# ------------------------------------- Our added functions -------------------------------------\n",
    "# summing 2 sigmoids to model initial acceptance and higher acceptance in order to model user behavior of wanting to have some margin from min requirements\n",
    "\n",
    "def f_tot(x, w, b, slope_low, slope_high, Thresh_low, Thresh_high, acp_reward):\n",
    "    # acp_reward and 1-acp_reward must be explicitly stated as positive to make the DCP ruleset\n",
    "    # complie the expression as convex, otherwise it may be non-convex\n",
    "    return cp.pos(acp_reward) * f(x, w, b, slope_low, Thresh_low)+ cp.pos(1-acp_reward) * f(x, w, b, slope_high, Thresh_high)\n",
    "\n",
    "def g_tot(x, w, b, slope_low, slope_high, Thresh_low, Thresh_high, acp_reward):\n",
    "    # acp_reward and 1-acp_reward must be explicitly stated as positive to make the DCP ruleset\n",
    "    # complie the expression as convex, otherwise it may be non-convex\n",
    "    return cp.pos(acp_reward) * g(x, w, b, slope_low, Thresh_low)+ cp.pos(1-acp_reward) * g(x, w, b, slope_high, Thresh_high)\n",
    "\n",
    "def f_tot_derivative(x, w, b, slope_low, slope_high, Thresh_low, Thresh_high, acp_reward):\n",
    "    # acp_reward and 1-acp_reward must be explicitly stated as positive to make the DCP ruleset\n",
    "    # complie the expression as convex, otherwise it may be non-convex\n",
    "    f_der = cp.pos(acp_reward) * f_derivative(x, w, b, slope_low, Thresh_low) + cp.pos(1-acp_reward) * f_derivative(x, w, b, slope_high, Thresh_high)\n",
    "    return f_der\n",
    "\n",
    "def f_tot_batch(x, w, b, slope_low, slope_high, Thresh_low, Thresh_high, acp_reward):\n",
    "    # acp_reward and 1-acp_reward must be explicitly stated as positive to make the DCP ruleset\n",
    "    # complie the expression as convex, otherwise it may be non-convex\n",
    "    return cp.pos(acp_reward) * f_batch(x, w, b, slope_low, Thresh_low)+ cp.pos(1-acp_reward) * f_batch(x, w, b, slope_high, Thresh_high)\n",
    "\n",
    "def g_tot_batch(x, w, b, slope_low, slope_high, Thresh_low, Thresh_high, acp_reward):\n",
    "    # expr1 = cp.pos(acp_reward) * g_batch(x, w, b, slope_low, Thresh_low)\n",
    "    # expr2 = cp.pos(1-acp_reward) * g_batch(x, w, b, slope_high, Thresh_high)\n",
    "    # expr_tot = expr1 + expr2\n",
    "    # print('expr1')\n",
    "    # print('DCP?', expr1.is_dcp())\n",
    "    # print('expr2')\n",
    "    # print('DCP?', expr2.is_dcp())\n",
    "    # print('expr_tot')\n",
    "    # print('DCP?', expr_tot.is_dcp())\n",
    "    # acp_reward and 1-acp_reward must be explicitly stated as positive to make the DCP ruleset\n",
    "    # complie the expression as convex, otherwise it may be non-convex\n",
    "    return cp.pos(acp_reward) * g_batch(x, w, b, slope_low, Thresh_low)+ cp.pos(1-acp_reward) * g_batch(x, w, b, slope_high, Thresh_high)\n",
    "\n",
    "def f_tot_derivative_batch(x, w, b, slope_low, slope_high, Thresh_low, Thresh_high, acp_reward):\n",
    "    return acp_reward * f_derivative_batch(x, w, b, slope_low, Thresh_low)+ (1-acp_reward) * f_derivative_batch(x, w, b, slope_high, Thresh_high)\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCP classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a CCP class based on the one implemented in the paper referenced above.\n",
    "\n",
    "Convex-Concave Procedure (in short CCP) is an iterative method for solving optimization problems that are expressed as a difference of convex functions, like the one we have in our problem.\n",
    "\n",
    "It does so by iterating through a sequence of concave-relaxed problems (using Taylor series to linearize on of the functions), a process that guarantees convergence to local maxima.\n",
    "\n",
    "We use $h(r)$ which is **a linear combination** of the sigmoid-like proxy described above to model the users behavior.\n",
    "\n",
    "As reminded above, this sigmoid function can be written as a difference of convex functions and is therefore perfect for CCP. \n",
    "\n",
    "Because $h(r)$ is a linear combination of sigmoids, it can also be discribed as a difference of convex functions and we can use CCP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T08:45:57.984890900Z",
     "start_time": "2024-05-12T08:45:57.481001600Z"
    }
   },
   "outputs": [],
   "source": [
    "class CCP_rank:\n",
    "    def __init__(self, x_dim, batch_size, funcs, scale):\n",
    "        self.f_derivative = funcs[\"f_derivative\"]\n",
    "        self.g = funcs[\"g\"]\n",
    "        self.c = funcs[\"c\"]\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # self.x = cp.Variable((batch_size, x_dim))\n",
    "        # self.xt = cp.Parameter((batch_size, x_dim))\n",
    "        # self.r = cp.Parameter((batch_size, x_dim)) # old reference point (initial x)\n",
    "        self.x = cp.Variable((batch_size, x_dim))\n",
    "        self.xt = cp.Parameter((batch_size, x_dim))\n",
    "        self.r = cp.Parameter((batch_size, x_dim))\n",
    "        \n",
    "        self.w = cp.Parameter(x_dim)\n",
    "        self.b = cp.Parameter(1) # bias parameter\n",
    "        # -------------------- adding our function's params --------------------\n",
    "        self.slope_low = cp.Parameter(1) # scale of the low threshold sigmoid\n",
    "        self.slope_high = cp.Parameter(1) # scale of the high threshold sigmoid\n",
    "        self.T_low = cp.Parameter(1) # low threshold of the sigmoid\n",
    "        self.T_high = cp.Parameter(1) # high threshold of the sigmoid\n",
    "        self.acp_reward = cp.Parameter(1) # defines the reward for passing initial threshhold - q in the equations \n",
    "        # ----------------------------------------------------------------------\n",
    "\n",
    "        # -------------------- defining our target function --------------------\n",
    "        # target = cp.diag(self.x@(self.f_derivative(self.xt, self.w, self.b, \n",
    "        #                 self.slope_low, self.slope_high, self.T_low, self.T_high, self.acp_reward).T)) - self.g(self.x, self.w,\n",
    "        #                 self.b, self.slope_low, self.slope_high, self.T_low, self.T_high, self.acp_reward)-self.c(self.x, self.r,\n",
    "        #                 x_dim, scale)\n",
    "        f = cp.diag(self.x@(self.f_derivative(self.xt, self.w, self.b, \n",
    "                        self.slope_low, self.slope_high, self.T_low, self.T_high, self.acp_reward).T))\n",
    "        g = self.g(self.x, self.w,\n",
    "                        self.b, self.slope_low, self.slope_high, self.T_low, self.T_high, self.acp_reward)\n",
    "        cost = self.c(self.x, self.r, x_dim, scale)\n",
    "        target = cp.diag(self.x@(self.f_derivative(self.xt, self.w, self.b, \n",
    "                        self.slope_low, self.slope_high, self.T_low, self.T_high, self.acp_reward).T)) - self.g(self.x, self.w,\n",
    "                        self.b, self.slope_low, self.slope_high, self.T_low, self.T_high, self.acp_reward) - self.c(self.x, self.r,\n",
    "                        x_dim, scale)\n",
    "        # target = - self.g(self.x, self.w,\n",
    "        #                 self.b, self.slope_low, self.slope_high, self.T_low, self.T_high, self.acp_reward)\n",
    "        # # ----------------------------------------------------------------------\n",
    "        constraints = [self.x >= X_LOWER_BOUND,\n",
    "                       self.x <= X_UPPER_BOUND]\n",
    "        # define the problem's objective\n",
    "        self.prob = cp.Problem(cp.Maximize(cp.sum(target)), constraints)\n",
    "\n",
    "    def ccp(self, r):\n",
    "        \"\"\"\n",
    "        numpy to numpy\n",
    "        \"\"\"\n",
    "        self.xt.value = r\n",
    "        self.r.value = r\n",
    "        result = self.prob.solve()\n",
    "        diff = np.linalg.norm(self.xt.value - self.x.value)\n",
    "        cnt = 0\n",
    "        while diff > 0.001 and cnt < 100:\n",
    "            cnt += 1\n",
    "            self.xt.value = self.x.value\n",
    "            result = self.prob.solve()\n",
    "            diff = np.linalg.norm(self.x.value - self.xt.value)/self.batch_size\n",
    "        return self.x.value\n",
    "\n",
    "    def optimize_X(self, X, w, b, slope_low, slope_high, T_low, T_high, acp_reward):\n",
    "        \"\"\"\n",
    "        tensor to tensor\n",
    "        \"\"\"\n",
    "        w = w.detach().numpy()\n",
    "        b = b.detach().numpy()\n",
    "        T_low = T_low.detach().numpy()\n",
    "        T_high = T_high.detach().numpy()\n",
    "        \n",
    "\n",
    "        # converting our params into numpy arrays with 1 value\n",
    "        slope_low = np.full(1, slope_low)\n",
    "        slope_high = np.full(1, slope_high)\n",
    "        T_low = np.full(1, T_low)\n",
    "        T_high = np.full(1, T_high)\n",
    "        acp_reward = np.full(1, acp_reward)\n",
    "\n",
    "        X = X.numpy()\n",
    "\n",
    "        self.w.value = w\n",
    "        self.b.value = b\n",
    "        self.slope_low.value = slope_low\n",
    "        self.slope_high.value = slope_high\n",
    "        self.T_low.value = T_low\n",
    "        self.T_high.value = T_high\n",
    "        self.acp_reward.value = acp_reward\n",
    "\n",
    "        # return torch.stack([torch.from_numpy(self.ccp(x)) for x in X])\n",
    "\n",
    "        return torch.from_numpy(self.ccp(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta \n",
    "This module uses the CCP procedure to compute the user responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T08:45:58.012640500Z",
     "start_time": "2024-05-12T08:45:57.505904200Z"
    }
   },
   "outputs": [],
   "source": [
    "class DELTA():\n",
    "\n",
    "    def __init__(self, x_dim, funcs, scale, slope_low, slope_high, acp_reward):\n",
    "        self.g = funcs[\"g\"]\n",
    "        self.c = funcs[\"c\"]\n",
    "\n",
    "        self.x = cp.Variable(x_dim)\n",
    "        self.r = cp.Parameter(x_dim, value = np.random.randn(x_dim))\n",
    "        self.w = cp.Parameter(x_dim, value = np.random.randn(x_dim))\n",
    "        self.b = cp.Parameter(1, value = np.random.randn(1))\n",
    "        self.f_der = cp.Parameter(x_dim, value = np.random.randn(x_dim))\n",
    "        # -------------------- adding our function's params --------------------\n",
    "        self.slope_low = slope_low # scale of the low threshold sigmoid\n",
    "        self.slope_high = slope_high # scale of the high threshold sigmoid\n",
    "        self.T_low = cp.Parameter(1) # low threshold of the sigmoid\n",
    "        self.T_high = cp.Parameter(1) # high threshold of the sigmoid\n",
    "        self.acp_reward = acp_reward # the relation between the 2 slopes - defines the reward for passing initial threshhold\n",
    "        # ----------------------------------------------------------------------\n",
    "\n",
    "        # -------------------- defining our target function --------------------\n",
    "        target = self.x@self.f_der-self.g(self.x, self.w, self.b, \n",
    "                        self.slope_low, self.slope_high, self.T_low, \n",
    "                        self.T_high, self.acp_reward)-self.c(self.x, self.r, x_dim, scale)\n",
    "        # ----------------------------------------------------------------------\n",
    "        constraints = [self.x >= X_LOWER_BOUND,\n",
    "                       self.x <= X_UPPER_BOUND]\n",
    "        objective = cp.Maximize(target)\n",
    "        problem = cp.Problem(objective, constraints)\n",
    "        self.layer = CvxpyLayer(problem, parameters=[self.r, self.w, self.b, self.f_der, self.T_low, self.T_high], variables=[self.x])\n",
    "        \n",
    "\n",
    "    def optimize_X(self, X, w, b, F_DER, T_low, T_high):\n",
    "        return self.layer(X, w, b, F_DER, T_low, T_high)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T09:19:59.096866700Z",
     "start_time": "2024-05-12T09:19:59.079288400Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyStrategicModel(torch.nn.Module):\n",
    "    def __init__(self, batch_size, env, strategic=False):\n",
    "        torch.manual_seed(0)\n",
    "        np.random.seed(0)\n",
    "\n",
    "        super(MyStrategicModel, self).__init__()\n",
    "        self.env = env\n",
    "        self.x_dim = env.n_features\n",
    "        self.batch_size = batch_size\n",
    "        # not sure why test slopes are different from test and train - still done here because original SCMP did it \n",
    "        self.train_slope_low, self.train_slope_high, self.test_slope_low, self.test_slope_high = env.slope_low, env.slope_high, 5*env.slope_low, 5*env.slope_high\n",
    "        self.w = torch.nn.parameter.Parameter(math.sqrt(1/self.x_dim)*(1-2*torch.rand(self.x_dim, dtype=torch.float64, requires_grad=True)))\n",
    "        self.b = torch.nn.parameter.Parameter(math.sqrt(1/self.x_dim)*(1-2*torch.rand(1, dtype=torch.float64, requires_grad=True)))\n",
    "        self.acp_reward = env.acp_reward\n",
    "        self.strategic = strategic\n",
    "        self.ccp = CCP_rank(self.x_dim, batch_size, env.funcs_batch, env.scale)\n",
    "        self.delta = DELTA(self.x_dim, env.funcs, env.scale, self.train_slope_low, self.train_slope_high, self.acp_reward)\n",
    "        self.ccp_time = 0\n",
    "        self.total_time = 0\n",
    "        \n",
    "        \n",
    "    def forward(self, X, use_delta=False, evaluation=False):\n",
    "        \n",
    "        if self.strategic:\n",
    "            t1 = time.time()\n",
    "            # currently not distinguishing between train and test slopes\n",
    "            Xt, X_opt = self.env.full_dynamic_update(X, self.w, self.b, use_delta)\n",
    "            \n",
    "            self.ccp_time += time.time()-t1\n",
    "            X_opt = Xt if evaluation else X_opt\n",
    "            output = self.score(X_opt)\n",
    "        else:\n",
    "            output = self.score(X)\n",
    "        return output\n",
    "\n",
    "    # def optimize_X(self, X, evaluation=False):\n",
    "    #     slope = self.eval_slope if evaluation else self.train_slope\n",
    "    #     return self.ccp.optimize_X(X, self.w, self.b, slope)\n",
    "\n",
    "    def normalize_weights(self):\n",
    "        with torch.no_grad():\n",
    "            norm = torch.sqrt(torch.sum(self.w**2) + self.b**2)\n",
    "            self.w /= norm\n",
    "            self.b /= norm\n",
    "\n",
    "    def score(self, x):\n",
    "        return x@self.w + self.b\n",
    "\n",
    "    def get_f_ders(self, XT, slope):\n",
    "        nablas = 0.5*slope*((slope*self.score(XT) + 1)/torch.sqrt((slope*self.score(XT) + 1)**2 + 1))\n",
    "        return torch.reshape(nablas, (len(nablas), 1))@torch.reshape(self.w, (1, len(self.w)))\n",
    "\n",
    "    def calc_accuracy(self, R, R_pred):\n",
    "        # calculating acceptance label from ratings\n",
    "        Y = self.rating_to_accept(R)\n",
    "        Y_pred = self.rating_to_accept(R_pred)\n",
    "\n",
    "        # calculating accuracy based on Y and Y_pred\n",
    "        temp = Y - Y_pred\n",
    "        acc = len(temp[temp == 0])*1./len(Y)\n",
    "        return acc\n",
    "    \n",
    "    def calc_burden(self, X_0, Y):\n",
    "        # calculating the burden in a similar fashion to the original paper\n",
    "        X_t, _ = self.env.full_dynamic_update(X_0, self.w, self.b, use_delta=False)\n",
    "        # i.e., only taking those who were supposed to get accepted\n",
    "        X_0_pos = X_0[Y==1]\n",
    "        X_t_pos = X_t[Y==1]\n",
    "        if len(X_0_pos) == 0:\n",
    "            return 0\n",
    "        # and measure how much they moved (although they are supposed to get accepted without effort) in order to get accepted\n",
    "        return torch.mean(torch.sum((X_0_pos-X_t_pos)**2, dim=1)).detach().numpy()\n",
    "\n",
    "    \n",
    "    # convert rating vector to acceptance\n",
    "    def rating_to_accept(self, R):\n",
    "        # calculating Y_pred out of score_pred\n",
    "        Y = np.zeros_like(R)\n",
    "        # getting the top-k values\n",
    "        top_k_ranking_indices = np.argsort(R)[-self.env.k:]\n",
    "        Y[top_k_ranking_indices] = 1\n",
    "        return Y\n",
    "        \n",
    "    # def evaluate(self, X, Y):\n",
    "    #     return self.calc_accuracy(Y, self.forward(X, evaluation=True))\n",
    "\n",
    "    # we use mean squared loss between provided ratings\n",
    "    def loss(self, Y, Y_pred):\n",
    "        return torch.mean((Y-Y_pred) ** 2)\n",
    "\n",
    "    def save_model(self, train_errors, val_errors, train_losses, val_losses, info, path, comment=None):\n",
    "        if comment is not None:\n",
    "            path += \"/\" + comment\n",
    "\n",
    "        filename = path + \"/model.pt\"\n",
    "        if not os.path.exists(os.path.dirname(filename)):\n",
    "            os.makedirs(os.path.dirname(filename))\n",
    "        torch.save(self.state_dict(), filename)\n",
    "\n",
    "        pd.DataFrame(np.array(train_errors)).to_csv(path + '/train_errors.csv')\n",
    "        pd.DataFrame(np.array(val_errors)).to_csv(path + '/val_errors.csv')\n",
    "        pd.DataFrame(np.array(train_losses)).to_csv(path + '/train_losses.csv')\n",
    "        pd.DataFrame(np.array(val_losses)).to_csv(path + '/val_losses.csv')\n",
    "\n",
    "        with open(path + \"/info.txt\", \"w\") as f:\n",
    "            f.write(info)\n",
    "\n",
    "    def load_model(self, filename):\n",
    "        self.load_state_dict(torch.load(filename))\n",
    "        self.eval()\n",
    "\n",
    "    # we fit according to score as a proxy to the ranking for simplicity reasons\n",
    "    def fit(self, path, X, R, Xval, Rval, opt, opt_kwargs={\"lr\":1e-3}, batch_size=128, epochs=100, verbose=False, callback=None, comment=None):\n",
    "        # labels are the true rating \n",
    "        # loading the datasets\n",
    "        train_dset = TensorDataset(X, R)\n",
    "        train_loader = DataLoader(train_dset, batch_size=batch_size, shuffle=True)\n",
    "        test_dset = TensorDataset(Xval, Rval)\n",
    "        test_loader = DataLoader(test_dset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        # optimizing the NN\n",
    "        opt = opt(self.parameters(), **opt_kwargs)\n",
    "\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        train_errors = []\n",
    "        val_errors = []\n",
    "\n",
    "        # adding our score metrics (ndcg, precision, recall...)\n",
    "        our_train_metrics = []\n",
    "        our_test_metrics = []\n",
    "\n",
    "        # defining stopping conditions\n",
    "        # best_val_error = 1\n",
    "        best_val_loss = np.inf\n",
    "        consecutive_no_improvement = 0\n",
    "\n",
    "        # runnning epochs\n",
    "        total_time = time.time()\n",
    "        for epoch in range(epochs):\n",
    "            t1 = time.time()\n",
    "            batch = 1\n",
    "            train_losses.append([])\n",
    "            train_errors.append([])\n",
    "            for Xbatch, Rbatch in train_loader:\n",
    "#                 try:\n",
    "                opt.zero_grad()\n",
    "                Rbatch_pred = self.forward(Xbatch)\n",
    "                l = self.loss(Rbatch, Rbatch_pred)\n",
    "                l.backward()\n",
    "                opt.step()\n",
    "                train_losses[-1].append(l.item())\n",
    "                with torch.no_grad():\n",
    "                    # calculating accuracy\n",
    "                    e = self.calc_accuracy(Rbatch, Rbatch_pred)\n",
    "\n",
    "                    # calculating different scores to the ranking\n",
    "                    Y = self.rating_to_accept(Rbatch)\n",
    "                    Y_pred = self.rating_to_accept(Rbatch_pred)\n",
    "                    our_train_metrics.append({\n",
    "                        \"epoch num\" : epoch,\n",
    "                        \"accuracy\" : e,\n",
    "                        \"loss\" : l.item(),\n",
    "                        \"ndcg\" : ndcg_score(np.expand_dims(Rbatch, 0), np.expand_dims(Rbatch_pred, 0)),\n",
    "                        \"precision\" : precision_score(Y, Y_pred),\n",
    "                        \"recall\" : recall_score(Y, Y_pred),\n",
    "                        \"burden\" : self.calc_burden(Xbatch, Y),\n",
    "                    })\n",
    "                    \n",
    "                    train_errors[-1].append(1-e)\n",
    "                if verbose:\n",
    "                    print(\"batch %03d / %03d | loss: %3.5f | err: %3.5f\" %\n",
    "                          (batch, len(train_loader), np.mean(train_losses[-1]), np.mean(train_errors[-1])))\n",
    "                batch += 1\n",
    "                if callback is not None:\n",
    "                    callback()\n",
    "#                 except:\n",
    "#                     print(\"failed\")\n",
    "\n",
    "            with torch.no_grad():\n",
    "                total_loss = 0\n",
    "                total_error = 0\n",
    "                batch = 0\n",
    "                for Xbatch, Rbatch in test_loader:\n",
    "#                     try:\n",
    "                    Rval_pred = self.forward(Xbatch, evaluation=True)\n",
    "                    val_loss = self.loss(Rbatch, Rval_pred).item()\n",
    "                    total_loss += val_loss\n",
    "                    val_error = 1-self.calc_accuracy(Rbatch, Rval_pred)\n",
    "                    total_error += val_error\n",
    "                    batch += 1\n",
    "#                     except:\n",
    "#                         print(\"failed\")\n",
    "                avg_loss = total_loss/batch\n",
    "                avg_error = total_error/batch\n",
    "                # calculating different scores to the ranking\n",
    "                Y = self.rating_to_accept(Rbatch)\n",
    "                Y_pred = self.rating_to_accept(Rval_pred)\n",
    "                our_test_metrics.append({\n",
    "                    \"epoch num\" : epoch,\n",
    "                    \"accuracy\" : 1 - avg_error,\n",
    "                    \"loss\" : avg_loss,\n",
    "                    \"ndcg\" : ndcg_score(np.expand_dims(Rbatch, 0), np.expand_dims(Rval_pred, 0)),\n",
    "                    \"precision\" : precision_score(Y, Y_pred),\n",
    "                    \"recall\" : recall_score(Y, Y_pred),\n",
    "                    \"burden\" : self.calc_burden(Xbatch, Y),\n",
    "                })\n",
    "                val_losses.append(avg_loss)\n",
    "                val_errors.append(avg_error)\n",
    "                if avg_loss < best_val_loss:\n",
    "                        consecutive_no_improvement = 0\n",
    "                        best_val_error = avg_error\n",
    "                        info = \"training time in seconds: {}\\nepoch: {}\\nbatch size: {}\\nslope low: {}\\nslope high: {}\\nlearning rate: {}\\nvalidation loss: {}\\nvalidation error: {}\\n\".format(\n",
    "                        time.time()-total_time, epoch, batch_size, self.train_slope_low, self.train_slope_high, opt_kwargs[\"lr\"], avg_loss, avg_error)\n",
    "                        self.save_model(train_errors, val_errors, train_losses, val_losses, info, path, comment)\n",
    "                        print(\"model saved!\")\n",
    "\n",
    "                else:\n",
    "                    consecutive_no_improvement += 1\n",
    "                    if consecutive_no_improvement >= 4:\n",
    "                        break\n",
    "\n",
    "            t2 = time.time()\n",
    "            if verbose:\n",
    "                print(\"------------- epoch %03d / %03d | time: %03d sec | loss: %3.5f | err: %3.5f\" % (epoch + 1, epochs, t2-t1, val_losses[-1], val_errors[-1]))\n",
    "\n",
    "        self.total_time = time.time()-total_time\n",
    "        print(\"training time: {} seconds\".format(self.total_time))\n",
    "        # returning our metrics in addition to the errors\n",
    "        return our_train_metrics, our_test_metrics\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation\n",
    "- user features generated randomly\n",
    "- ground truth rating model is $r(x)=u^Tx$ \n",
    "- observed noisy ratings $\\tilde{r}(x)=r(x)+\\epsilon$, where $\\epsilon \\sim \\mathcal{N}(0,\\sigma^2_\\epsilon)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Training Environment\n",
    "\n",
    "Each training step will include several dynamic iterations (user feature updates) and after that a single update of the system features $\\theta$.\n",
    "\n",
    "Pseudocode of the training:\n",
    "\n",
    "- until model convergence:\n",
    "    - for $t = 0:T$\n",
    "        - Get $T_{low},T_{high}$ from $r_{\\theta}(\\cdot)$ and $x_t$\n",
    "        - $x_{t+1} = \\Delta_h(x_t,T_{low},T_{high})$\n",
    "    - Update model based on $x_T,r$\n",
    "    - $w,b = GD(x_T,r)$\n",
    "\n",
    "In test time we will evaluate features after the dynamic iteration i.e., $x_T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T08:45:58.015192900Z",
     "start_time": "2024-05-12T08:45:57.727485900Z"
    }
   },
   "outputs": [],
   "source": [
    "class RankingEnv():\n",
    "    \"\"\"\n",
    "    Strategic Classification Environment\n",
    "    \"\"\"\n",
    "    def __init__(self, noisyscale, n_features, k, k_tag, n_users, slope_low, slope_high, acp_reward, funcs, funcs_batch, scale):\n",
    "        self.noisyscale = noisyscale\n",
    "        self.n_features = n_features\n",
    "        self.k = k  # k is number of accepted users\n",
    "        self.k_tag = k_tag  # k' < k sets the threshold of confidant acceptance\n",
    "        self.system_attributes = torch.randn(size=(n_features,))*0.1  # u system rating vector, multiplying in 0.1, the scale\n",
    "        \n",
    "        # system variables \n",
    "        self.w = torch.nn.parameter.Parameter(math.sqrt(1/n_features)*(1-2*torch.rand(n_features, dtype=torch.float64, requires_grad=True)))\n",
    "        self.b = torch.nn.parameter.Parameter(math.sqrt(1/n_features)*(1-2*torch.rand(1, dtype=torch.float64, requires_grad=True)))\n",
    "        \n",
    "        # Delta parameters\n",
    "        self.slope_low = slope_low # scale of the low threshold sigmoid\n",
    "        self.slope_high = slope_high # scale of the high threshold sigmoid\n",
    "        self.acp_reward = acp_reward # the relation between the 2 slopes - defines the reward for passing initial threshhold\n",
    "        self.scale = scale  # cost function scale\n",
    "        self.funcs = funcs\n",
    "        self.funcs_batch = funcs_batch\n",
    "        self.ccp = CCP_rank(n_features, batch_size=n_users, funcs=funcs_batch, scale=scale)\n",
    "        self.delta = DELTA(n_features, funcs, scale, slope_low, slope_high, acp_reward)\n",
    "\n",
    "        \n",
    "        # user variables \n",
    "        self.n_users = n_users\n",
    "        # self.users_initial = self.generate_users(n_users=n_users)\n",
    "        # self.users_current = self.users_initial\n",
    "        self.t = 0  # time indicator\n",
    "        self.T_max = 5  #  number of dynamic iterations\n",
    "    \n",
    "    def generate_dataset(self):\n",
    "        X = self.generate_users(self.n_users)\n",
    "        R = self.rating(X)\n",
    "        y = self.get_true_accepted(X)\n",
    "        return X, R, y\n",
    "        \n",
    "    def generate_users(self, n_users):\n",
    "        return torch.randn(size = (n_users, self.n_features)) * 0.1 # multiplying in 0.1, the scale\n",
    "    \n",
    "    # def get_users_current(self):\n",
    "    #     return self.users_current\n",
    "    \n",
    "    # def get_users_initial(self):\n",
    "    #     return self.users_initial\n",
    "    \n",
    "    def rating(self, users):\n",
    "        # return noisy users rating, when the noise is normally distributed\n",
    "        clean_ratings = users@self.system_attributes.T\n",
    "        noise = torch.randn_like(clean_ratings) * self.noisyscale # multiplying in the noisyscale\n",
    "        return clean_ratings + noise\n",
    "    \n",
    "    def get_thresh(self, X):\n",
    "        ranking = self.score(X)\n",
    "        # reversing the sort into a descending order\n",
    "        sorted_ranking , _= torch.sort(ranking, descending=True)\n",
    "        # calculate thresholds from k and k_tag\n",
    "        return sorted_ranking[self.k-1].reshape(1), sorted_ranking[self.k_tag-1].reshape(1)\n",
    "    \n",
    "    # returns ground truth ratings for users\n",
    "    def get_true_accepted(self, X):\n",
    "        ranking = self.rating(X)\n",
    "        acceptance = torch.zeros_like(ranking)\n",
    "        # sort ranking in descending order\n",
    "        _ , sorted_indices = torch.sort(ranking, descending=True)\n",
    "        acceptance[sorted_indices[:self.k]] = 1\n",
    "        return acceptance\n",
    "    \n",
    "    def user_features_update(self, X, Xt, use_delta=False):\n",
    "        # update features based on the response function\n",
    "        self.t += 1\n",
    "        # update features\n",
    "        T_low, T_high = self.get_thresh(Xt)\n",
    "        XT = self.ccp.optimize_X(X, self.w, self.b, self.slope_low, self.slope_high, T_low,\n",
    "                                 T_high, self.acp_reward)\n",
    "        if use_delta:\n",
    "            F_DER = self.get_f_ders(XT, self.slope_low, self.slope_high, T_low, T_high)\n",
    "            X_opt = self.delta.optimize_X(X, self.w, self.b, F_DER, T_low, T_high) # Xopt should be equal to XT but repeat for gradients\n",
    "            return X_opt # this includes the whole dynamic process in the derivatives\n",
    "        else:\n",
    "            return XT \n",
    "        \n",
    "    def update_wb(self, w, b):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        self.t = 0  # reset time as new paramemters show \n",
    "    \n",
    "    def full_dynamic_update(self, X, w, b, use_delta=False):\n",
    "        self.update_wb(w, b)\n",
    "        Xt = X\n",
    "        for _ in range(self.T_max):\n",
    "            Xt = self.user_features_update(X, Xt, use_delta=use_delta)\n",
    "        # if delta wasn't used it must be used in the last step\n",
    "        X_opt = Xt\n",
    "        if not use_delta:\n",
    "            T_low, T_high = self.get_thresh(Xt)\n",
    "            F_DER = self.get_f_ders(Xt, self.slope_low, self.slope_high, T_low, T_high)\n",
    "            X_opt = self.delta.optimize_X(X, self.w, self.b, F_DER, T_low, T_high)\n",
    "        # returning both in order to support evaluation condition in forward\n",
    "        return Xt, X_opt\n",
    "    \n",
    "    \n",
    "    def get_f_ders_helper(self, XT, slope, T):\n",
    "        nablas = 0.5*slope*((slope*(self.score(XT) - T) + 1)/torch.sqrt((slope*(self.score(XT) - T) + 1)**2 + 1))\n",
    "        return torch.reshape(nablas, (len(nablas), 1))@torch.reshape(self.w, (1, len(self.w)))\n",
    "    \n",
    "    def get_f_ders(self, XT, slope_low, slope_high, T_low, T_high):\n",
    "        return (self.acp_reward*self.get_f_ders_helper(XT, slope_low, T_low) + \n",
    "                (1-self.acp_reward)*self.get_f_ders_helper(XT, slope_high, T_high))\n",
    "    \n",
    "    def score(self, x):\n",
    "        return x@self.w + self.b\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T09:01:57.057254800Z",
     "start_time": "2024-05-12T09:01:57.012429100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize env\n",
    "funcs = {\"f\": f_tot, \"g\": g_tot, \"f_derivative\": f_tot_derivative, \"c\": c, \"score\": score}\n",
    "# funcs = {\"f\": f_tot, \"g\": g, \"f_derivative\": f_tot_derivative, \"c\": c, \"score\": score}\n",
    "funcs_batch = {\"f\": f_tot_batch, \"g\": g_tot_batch, \"f_derivative\": f_tot_derivative_batch, \"c\": c_batch, \"score\": score}\n",
    "env_params = {'noisyscale' : 0.01,\n",
    "              'n_features' : 5,\n",
    "              'k' : 40,\n",
    "              'k_tag' : 20,\n",
    "              'n_users': 400,\n",
    "              'slope_low' : 40,\n",
    "              'slope_high' : 10,\n",
    "              'acp_reward' : 0.6,\n",
    "              'funcs' : funcs,\n",
    "              'funcs_batch' : funcs_batch,\n",
    "              'scale' : 1}\n",
    "\n",
    "rank_env = RankingEnv(**env_params)\n",
    "\n",
    "# TODO: integrate eval_slope_low and eval_slope_high into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T09:01:58.767999100Z",
     "start_time": "2024-05-12T09:01:58.759498400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ori Anvar\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:51: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3281.)\n"
     ]
    }
   ],
   "source": [
    "# generate train and test sets\n",
    "X_train, R_train, y_train = rank_env.generate_dataset()\n",
    "X_test, R_test, y_test = rank_env.generate_dataset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T09:19:59.021201200Z",
     "start_time": "2024-05-12T09:02:00.651442900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now training classical model\n",
      "batch 001 / 001 | loss: 0.07329 | err: 0.19500\n",
      "model saved!\n",
      "------------- epoch 001 / 010 | time: 014 sec | loss: 0.02971 | err: 0.19500\n",
      "batch 001 / 001 | loss: 0.02913 | err: 0.19000\n",
      "model saved!\n",
      "------------- epoch 002 / 010 | time: 016 sec | loss: 0.00632 | err: 0.18000\n",
      "batch 001 / 001 | loss: 0.00607 | err: 0.17500\n",
      "model saved!\n",
      "------------- epoch 003 / 010 | time: 014 sec | loss: 0.00161 | err: 0.15500\n",
      "batch 001 / 001 | loss: 0.00162 | err: 0.13500\n",
      "model saved!\n",
      "------------- epoch 004 / 010 | time: 019 sec | loss: 0.00832 | err: 0.12500\n",
      "batch 001 / 001 | loss: 0.00843 | err: 0.11000\n",
      "model saved!\n",
      "------------- epoch 005 / 010 | time: 022 sec | loss: 0.01647 | err: 0.10500\n",
      "batch 001 / 001 | loss: 0.01652 | err: 0.07000\n",
      "model saved!\n",
      "------------- epoch 006 / 010 | time: 022 sec | loss: 0.01971 | err: 0.07000\n",
      "batch 001 / 001 | loss: 0.01963 | err: 0.04500\n",
      "model saved!\n",
      "------------- epoch 007 / 010 | time: 017 sec | loss: 0.01745 | err: 0.05500\n",
      "batch 001 / 001 | loss: 0.01725 | err: 0.03500\n",
      "model saved!\n",
      "------------- epoch 008 / 010 | time: 020 sec | loss: 0.01206 | err: 0.05000\n",
      "batch 001 / 001 | loss: 0.01180 | err: 0.05000\n",
      "model saved!\n",
      "------------- epoch 009 / 010 | time: 017 sec | loss: 0.00634 | err: 0.06000\n",
      "batch 001 / 001 | loss: 0.00611 | err: 0.06000\n",
      "model saved!\n",
      "------------- epoch 010 / 010 | time: 017 sec | loss: 0.00239 | err: 0.07000\n",
      "training time: 184.3111481666565 seconds\n",
      "now training strategic model\n",
      "batch 001 / 001 | loss: 0.00903 | err: 0.19500\n",
      "model saved!\n",
      "------------- epoch 001 / 010 | time: 042 sec | loss: 0.01026 | err: 0.20000\n",
      "batch 001 / 001 | loss: 0.00323 | err: 0.19500\n",
      "model saved!\n",
      "------------- epoch 002 / 010 | time: 031 sec | loss: 0.01536 | err: 0.19000\n",
      "batch 001 / 001 | loss: 0.00622 | err: 0.19000\n",
      "model saved!\n",
      "------------- epoch 003 / 010 | time: 034 sec | loss: 0.00820 | err: 0.19000\n",
      "batch 001 / 001 | loss: 0.00216 | err: 0.18000\n",
      "model saved!\n",
      "------------- epoch 004 / 010 | time: 038 sec | loss: 0.00238 | err: 0.19000\n",
      "batch 001 / 001 | loss: 0.00125 | err: 0.17500\n",
      "model saved!\n",
      "------------- epoch 005 / 010 | time: 040 sec | loss: 0.00096 | err: 0.18000\n",
      "batch 001 / 001 | loss: 0.00327 | err: 0.17500\n",
      "model saved!\n",
      "------------- epoch 006 / 010 | time: 049 sec | loss: 0.00094 | err: 0.18000\n",
      "batch 001 / 001 | loss: 0.00382 | err: 0.17000\n",
      "model saved!\n",
      "------------- epoch 007 / 010 | time: 042 sec | loss: 0.00146 | err: 0.17500\n",
      "batch 001 / 001 | loss: 0.00216 | err: 0.16500\n",
      "model saved!\n",
      "------------- epoch 008 / 010 | time: 030 sec | loss: 0.00384 | err: 0.17500\n",
      "batch 001 / 001 | loss: 0.00098 | err: 0.16500\n",
      "model saved!\n",
      "------------- epoch 009 / 010 | time: 037 sec | loss: 0.00826 | err: 0.17500\n",
      "batch 001 / 001 | loss: 0.00157 | err: 0.16500\n",
      "model saved!\n",
      "------------- epoch 010 / 010 | time: 039 sec | loss: 0.01088 | err: 0.17500\n",
      "training time: 386.1843628883362 seconds\n"
     ]
    }
   ],
   "source": [
    "# define models \n",
    "model_classic = MyStrategicModel(batch_size=env_params['n_users'], env=rank_env, strategic=False)\n",
    "model_strategic = MyStrategicModel(batch_size=env_params['n_users'], env=rank_env, strategic=True)\n",
    "\n",
    "path_strategic = \"./tests/baseline/strategic\"\n",
    "path_classical = \"./tests/baseline/classical\"\n",
    "epochs = 10\n",
    "batch_size = env_params['n_users']\n",
    "total = []\n",
    "ccp = []\n",
    "\n",
    "print('now training classical model')\n",
    "classic_train_metrics, classic_test_metrics = model_classic.fit(path_classical, X_train, R_train, X_test, R_test,\n",
    "                    opt=torch.optim.Adam, opt_kwargs={\"lr\": (1e-1)},\n",
    "                    batch_size=batch_size, epochs=epochs, verbose=True,\n",
    "                   comment=\"batched\")\n",
    "\n",
    "print('now training strategic model')\n",
    "strategic_train_metrics, strategic_test_metrics = model_strategic.fit(path_strategic, X_train, R_train, X_test, R_test,\n",
    "                    opt=torch.optim.Adam, opt_kwargs={\"lr\": (1e-1)},\n",
    "                    batch_size=batch_size, epochs=epochs, verbose=True,\n",
    "                   comment=\"batched\")\n",
    "\n",
    "total_time = model_strategic.total_time\n",
    "ccp_time = model_strategic.ccp_time\n",
    "total.append(total_time)\n",
    "ccp.append(ccp_time)\n",
    "\n",
    "# saving baseline\n",
    "pd.DataFrame(np.array(total)).to_csv(path_strategic + '/total_timing_results.csv')\n",
    "pd.DataFrame(np.array(ccp)).to_csv(path_strategic + '/ccp_timing_results.csv')\n",
    "pd.DataFrame(classic_train_metrics).to_csv(path_classical + '/train_metrics.csv')\n",
    "pd.DataFrame(classic_test_metrics).to_csv(path_classical + '/test_metrics.csv')\n",
    "pd.DataFrame(strategic_train_metrics).to_csv(path_strategic + '/train_metrics.csv')\n",
    "pd.DataFrame(strategic_test_metrics).to_csv(path_strategic + '/test_metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Further Questions\n",
    "\n",
    "1. Goals:\n",
    "    - Develop a system capable of coping with contest behavior\n",
    "    - Deploy system on toy example with synthetic data\n",
    "    - Change contest parameters and study effect on precision and burden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: Accuracy for different slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now training strategic model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ori Anvar\\anaconda3\\lib\\site-packages\\cvxpy\\reductions\\solvers\\solving_chain.py:213: UserWarning: You are solving a parameterized problem that is not DPP. Because the problem is not DPP, subsequent solves will not be faster than the first one. For more information, see the documentation on Discplined Parametrized Programming, at\n",
      "\thttps://www.cvxpy.org/tutorial/advanced/index.html#disciplined-parametrized-programming\n",
      "  warnings.warn(dpp_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 001 / 001 | loss: 0.06211 | err: 0.23000\n",
      "model saved!\n",
      "------------- epoch 001 / 010 | time: 014 sec | loss: 0.02158 | err: 0.31000\n",
      "batch 001 / 001 | loss: 0.02284 | err: 0.25000\n",
      "model saved!\n",
      "------------- epoch 002 / 010 | time: 014 sec | loss: 0.00779 | err: 0.32000\n",
      "batch 001 / 001 | loss: 0.00781 | err: 0.26000\n",
      "model saved!\n",
      "------------- epoch 003 / 010 | time: 013 sec | loss: 0.01049 | err: 0.34000\n",
      "batch 001 / 001 | loss: 0.00927 | err: 0.27000\n",
      "model saved!\n",
      "------------- epoch 004 / 010 | time: 014 sec | loss: 0.01721 | err: 0.34000\n",
      "batch 001 / 001 | loss: 0.01533 | err: 0.25000\n",
      "model saved!\n",
      "------------- epoch 005 / 010 | time: 016 sec | loss: 0.02010 | err: 0.32000\n",
      "batch 001 / 001 | loss: 0.01807 | err: 0.24000\n",
      "model saved!\n",
      "------------- epoch 006 / 010 | time: 026 sec | loss: 0.01770 | err: 0.32000\n",
      "batch 001 / 001 | loss: 0.01583 | err: 0.23000\n",
      "model saved!\n",
      "------------- epoch 007 / 010 | time: 020 sec | loss: 0.01196 | err: 0.31000\n",
      "batch 001 / 001 | loss: 0.01057 | err: 0.22000\n",
      "model saved!\n",
      "------------- epoch 008 / 010 | time: 018 sec | loss: 0.00590 | err: 0.29000\n",
      "batch 001 / 001 | loss: 0.00510 | err: 0.22000\n"
     ]
    }
   ],
   "source": [
    "# defining different environments for different slopes\n",
    "slope_vals = [0.1, 1, 2, 5, 10]\n",
    "\n",
    "\n",
    "for slope_val in slope_vals:\n",
    "    # training with different slopes\n",
    "    env_params = {'noisyscale' : 0.01,\n",
    "                'n_features' : 5,\n",
    "                'k' : 40,\n",
    "                'k_tag' : 20,\n",
    "                'n_users': 200,\n",
    "                'slope_low' : slope_val,\n",
    "                'slope_high' : slope_val,\n",
    "                'acp_reward' : 0.6,\n",
    "                'funcs' : funcs,\n",
    "                'funcs_batch' : funcs_batch,\n",
    "                'scale' : 1}\n",
    "    \n",
    "    rank_env = RankingEnv(**env_params)\n",
    "    model = MyStrategicModel(batch_size=env_params['n_users'], env=rank_env, strategic=True)\n",
    "    \n",
    "    # generate train and test sets\n",
    "    X_train, R_train, y_train = rank_env.generate_dataset()\n",
    "    X_test, R_test, y_test = rank_env.generate_dataset()\n",
    "\n",
    "    slope_str = str(slope_val).replace('.', ',')\n",
    "    path_strategic = f\"./tests/slope_test_{slope_str}/strategic\"\n",
    "    epochs = 10\n",
    "    batch_size = env_params['n_users']\n",
    "    total = []\n",
    "    ccp = []\n",
    "\n",
    "    print('now training strategic model')\n",
    "    strategic_train_metrics, strategic_test_metrics = model.fit(path_strategic, X_train, R_train, X_test, R_test,\n",
    "                        opt=torch.optim.Adam, opt_kwargs={\"lr\": (1e-1)},\n",
    "                        batch_size=batch_size, epochs=epochs, verbose=True,\n",
    "                    comment=\"batched\")\n",
    "\n",
    "    total_time = model.total_time\n",
    "    ccp_time = model.ccp_time\n",
    "    total.append(total_time)\n",
    "    ccp.append(ccp_time)\n",
    "\n",
    "    # saving slope test results\n",
    "    pd.DataFrame(np.array(total)).to_csv(path_strategic + '/total_timing_results.csv')\n",
    "    pd.DataFrame(np.array(ccp)).to_csv(path_strategic + '/ccp_timing_results.csv')\n",
    "    pd.DataFrame(strategic_train_metrics).to_csv(path_strategic + '/train_metrics.csv')\n",
    "    pd.DataFrame(strategic_test_metrics).to_csv(path_strategic + '/test_metrics.csv')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.182940\n",
      "1    0.171937\n",
      "2    0.136249\n",
      "3    0.106766\n",
      "4    0.091648\n",
      "5    0.088112\n",
      "6    0.092169\n",
      "7    0.098549\n",
      "8    0.100385\n",
      "9    0.094162\n",
      "Name: burden, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtcAAAGDCAYAAADgeTwhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdd3yV5f3/8dcnG0gChCTsvcKSYUBUtlVRUSwVAbX9OiraatW6kFbrrq114Gqr/tpqrQy34lZkudkjQEJAIGFlMBMIWdfvj3OgkQYIkJM75+T9fDzy8Jxz3+ec932S0neuXPd1m3MOERERERE5eWFeBxARERERCRUq1yIiIiIi1UTlWkRERESkmqhci4iIiIhUE5VrEREREZFqonItIiIiIlJNVK5FJOSY2eVm9mkV9vu7md1TE5m8YmYvmdlD/tuDzSy9wrauZrbEzPaa2U1mVs/MZprZbjN73bvUx8/MnJl18jpHVZnZBjP7idc5RKT6RXgdQESkujnnXgVercJ+19dAnFrDOTcf6FrhoTuBOc65vgBm9nOgKdDEOVda0/nMzAGdnXOZNf3eIiLVRSPXIlIrmZl++T8K8znZf8PbAmmH3c84kWKt75eIiI/KtYjUGP+fwieb2Soz22lm/zKzGP+2YWaWbWaTzGwb8C//46PMbKmZ7TKzr83slAqv19rM3jKzXDPLN7Nn/Y9faWZf+m+bmT1pZjn+6Q7Lzaynf9uhKRP++9eaWaaZ7TCz98ysRYVtzsyuN7O1/uzPmZkd4TijzWyKmW3xf00xs2j/ttVmNqrCvhFmlmdm/fz3B/qPc5eZLTOzYRX2nWNmD5vZV8A+oEMl793XzBb7p3rMAGIqbBtmZtn+218Aw4FnzazAzKYBfwDG+e9f49/van/mnWb2iZm1PewzucHM1gJr/Y+lmNln/s8w3cwurbD/S/7P7QN/vu/MrKN/2zz/bsv87z+ukmPrZGZz/d/HPP/xVfb5NzSzf/t/Ljaa2d0HfxHx/2x8ZWbP+F9njZmdddhz/2FmW81ss5k9ZGbhlbxHCzPbb2YJh332eWYWaWYdzewL/89lnpm9amaNjpB3gJktNLM9ZrbdzJ6obD8RCQ4q1yJS0y4HzgU6Al2AuytsawYk4BtBnegvnP8ErgOaAM8D7/nLazjwPrARaAe0BKZX8n7nAEP879UIGAfkH76TmY0AHgEuBZr7X/fw1xsF9Ad6+/c79wjH+HtgINDHv++ACsc5DZhQYd9zgTzn3GIzawl8ADzk/xxuB940s6QK+/8cmAjE+TNWPIYo4B3gFf/zXwd+VllA59wIYD5wo3Mu1jk3AfgjMMN//x9mdjHwO2AMkOTff9phL3UxcBrQ3cwaAJ8BU4Fk/3H+1cx6VNh/AnA/0BjIBB725xni397b//6VFecHgU/9z20FPFPZsfkfb4jvl4+hwC+AqypsPw1YDyQC9wJvVSjJLwOlQCegL76fn18e/gbOuS3AN/z4870MeMM5VwIYvp+nFkA3oDVw3xHyPgU85ZyLx/e/i9eOsJ+IBAGVaxGpac8657KcczvwFauKRbMcuNc5d8A5tx+4FnjeOfedc67MOfcycABfcR2Ar7jc4ZwrdM4VOee+rOT9SvAV0RTAnHOrnXNbK9nvcuCfzrnFzrkDwGTgdDNrV2GfPznndjnnNgGz8ZXnylwOPOCcy3HO5eIrkz/3b5sKXGRm9f33L/M/BnAF8KFz7kPnXLlz7jNgIXB+hdd+yTmX5pwr9Ze4igYCkcAU51yJc+4NYMERMlbFdcAj/s+sFF/57lNx9Nq/fYf/+zUK2OCc+5c/32LgTeCSCvu/5Zz73v96r3Lkz7AyJfh+8WpxpO+3/5euccBk59xe59wG4HH++/kD5PDfz2gGkA5cYGZNgfOAW/w/UznAk8D4I+SZiv/n1/9XjPH+x3DOZTrnPvP/LOcCT+Ar+kc6rk5mluicK3DOfVvlT0REah2VaxGpaVkVbm/EV5APynXOFVW43xa4zT9FYpeZ7cI3AtjC/9+Nx5of7Jz7AngWeA7YbmYvmFl8Jbu2oMJIsHOuAN8Id8sK+2yrcHsfEHuEt/3Ra1HhOP0n660GLvQX7Iv4b7luC4w97HgH4RtJP6ji51fZ+252zrnD3vtEtQWeqpBlB74R2YqfSdZh+592WP7L8f1F4qCqfoaVudP//t+bWZqZXV3JPolAFP/7+VfMXNln1MKfPxLYWiH/8/hG4SvzBr5fwFrg++uIwze6j5klm9l0/9SSPcB//Nkqcw2+v6ysMbMFVmHakIgEH52AIiI1rXWF222ALRXuu8P2zQIeds49fPiLmNnpQBszi6hCwX4aeNrMkvH9yf0O4PAl+LbgK1cHX78Bvqkom49+OJU6+FoHTxY8/DgPTg0JA1ZVWB0jC3jFOXft0Q7nKNu2Ai3NzCqUxzbAuuPMf9DBz/9oK69UzJMFzHXOnX2C73dUzrlt+P6agZkNAj43s3mHrS6Sx39HuFf5H2vDj7+PlX1G7/nzHwASq3JSp3Nul/mWfLwU39SPaRVe8xF8n80pzrl8/xSbZ4/wOmuBCf554WOAN8ysiXOu8FgZRKT20ci1iNS0G8yslX+O6++ASk9K83sRuN7MTjOfBmZ2gZnFAd/jK5N/8j8eY2ZnHv4CZtbf//xIoBAoAsoqea+pwFVm1sd8Jx/+EfjOP63geE0D7jazJDNLxHei4H8qbJ+Oby7vr/jvqDX+fS40s3PNLNx/TMPMrFUV3/cbfPOFbzLfiZJj8E2fOVF/ByYfnDPtP9lv7FH2fx/oYmY/95/UF+n//LtV8f22U8lJmgeZ2dgKn8VOfOX1R99L51wZvl+gHjazOP8Ullv58eefjO8zivQfTzd803G24pvT/biZxZtZmP/ExCNN5wDf9+8X+OZeV/xexgEFwC7/XPo7jnJcV5hZknOuHNjlf7iyn1ERCQIq1yJS06biKzDr/V8PHWlH59xCfCOVz+IrU5nAlf5tZcCF+E482wRk45tre7h4fCV9J74//+cDj1XyXrPwjWa/ia+0d+TIc22P5SF8c6WXAyuAxVQ4Tn+J+wY4gwq/XDjnsoDR+H7pyMU3knoHVfy32jlXjG/k80p8xzsOeOsEjwHn3NvAn4Hp/qkNK/HNST7S/nvx/dIwHt9I/Tb/86Or+Jb3AS/7p2RcWsn2/sB3ZlaAb6T5ZufcD5Xs9xt8v0itB77E9zP3zwrbvwM64xvlfhi4xDl38CTXX+CbVrIK32f4Bj+elnO49/yvtd05t6zC4/cD/YDd+E5SPdr3YSSQ5j+up4Dxh02PEpEgYj+ediYiEjhmtgH4pXPuc6+zSN1kZlfi+xkc5HUWEQlNGrkWEREREakmKtciIiIiItVE00JERERERKqJRq5FRERERKqJyrWIiIiISDUJmYvIJCYmunbt2nkdQ0RERERC3KJFi/Kcc0mVbQuZct2uXTsWLlzodQwRERERCXFmtvFI2zQtRERERESkmqhci4iIiIhUE5VrEREREZFqEjJzrkVERETEOyUlJWRnZ1NUVOR1lGoTExNDq1atiIyMrPJzVK5FRERE5KRlZ2cTFxdHu3btMDOv45w05xz5+flkZ2fTvn37Kj9P00JERERE5KQVFRXRpEmTkCjWAGZGkyZNjnskXuVaRERERKpFqBTrg07keFSuRURERESqicq1iIiIiNSIYcOG1cqL/t1333089thj1fJaKtciIiIiItVE5VpEREREql1hYSEXXHABvXv3pmfPnsyYMeNH26dNm0avXr3o2bMnkyZNOvR4bGwst912G/369eOss84iNzcXgHXr1jFy5EhOPfVUBg8ezJo1ayp93927d9OuXTvKy8sB2LdvH61bt6akpIQXX3yR/v3707t3b372s5+xb9++aj9uleuTNH9tLtv3hM56jiIiIiLV4eOPP6ZFixYsW7aMlStXMnLkyEPbtmzZwqRJk/jiiy9YunQpCxYs4J133gF8pbxfv34sXryYoUOHcv/99wMwceJEnnnmGRYtWsRjjz3Gr3/960rft2HDhvTu3Zu5c+cCMHPmTM4991wiIyMZM2YMCxYsYNmyZXTr1o1//OMf1X7cKtcnoaSsnFtfW8aQR2fzwMxV5O494HUkERERkVqhV69efP7550yaNIn58+fTsGHDQ9sWLFjAsGHDSEpKIiIigssvv5x58+YBEBYWxrhx4wC44oor+PLLLykoKODrr79m7Nix9OnTh+uuu46tW7ce8b3HjRt3aKR8+vTph15v5cqVDB48mF69evHqq6+SlpZW7ceti8ichMjwMN68/gye+WItL3+zganfb+T/Tm/HxCEdaBIb7XU8EREREc906dKFRYsW8eGHHzJ58mTOOeecQ9ucc1V+HTOjvLycRo0asXTp0io956KLLmLy5Mns2LGDRYsWMWLECACuvPJK3nnnHXr37s1LL73EnDlzjuuYqkIj1yepTZP6/GVsbz6/dSjn9WzOi/PXM/jR2Tz68Rp2FhZ7HU9ERETEE1u2bKF+/fpcccUV3H777SxevPjQttNOO425c+eSl5dHWVkZ06ZNY+jQoQCUl5fzxhtvADB16lQGDRpEfHw87du35/XXXwd85XzZsmVHfO/Y2FgGDBjAzTffzKhRowgPDwdg7969NG/enJKSEl599dWAHLdGrqtJ+8QGPDmuDzcM78hTszL529x1/PubjVw9qD3XDGpPw3pVvya9iIiISLBbsWIFd9xxB2FhYURGRvK3v/2N22+/HYDmzZvzyCOPMHz4cJxznH/++YwePRqABg0akJaWxqmnnkrDhg0PTe949dVX+dWvfsVDDz1ESUkJ48ePp3fv3kd8/3HjxjF27NgfjU4/+OCDnHbaabRt25ZevXqxd+/eaj9uO55h+dosNTXV1aZ1E9O37eWpWRl8uGIbcTERXDu4A1ed2Y64GJVsERERCT2rV6+mW7duJ/06sbGxFBQUVEOi6lHZcZnZIudcamX7a1pIgHRtFsdfLz+VD28azMAOTXjiswwGPzqbv87JpPBAqdfxRERERCQAAlquzWykmaWbWaaZ3VXJ9iFmttjMSs3sksO2PWpmaWa22syetiC9WH33FvG8+ItUZt44iH5tGvPox+kMfnQ2L8xbx/7iMq/jiYiIiNQqxzNq/fDDD9OnT58ffT388MMBTHdsAZsWYmbhQAZwNpANLAAmOOdWVdinHRAP3A6855x7w//4GcBfgCH+Xb8EJjvn5hzp/WrbtJAjWbxpJ09+lsH8tXkkxkbzq2Edufy0NsREhnsdTUREROSEVde0kNqmNk0LGQBkOufWO+eKgenA6Io7OOc2OOeWA+WHPdcBMUAUEA1EAtsDmLXG9GvTmFeuOY3Xrz+dLk1jefD9VQz9y2z+/c0GDpRqJFtEREQkmAWyXLcEsircz/Y/dkzOuW+A2cBW/9cnzrnV1Z7QQ/3bJTD12oFMu3YgbRMa8Id30xj2lzm8+t1GiksP/11DRERERIJBIMt1ZXOkqzQHxcw6Ad2AVvgK+QgzG1LJfhPNbKGZLTx43flgc3rHJsy4biD/ueY0mjWM4fdvr2TE43N4bUEWJWUq2SIiIiLBJJDlOhtoXeF+K2BLFZ/7U+Bb51yBc64A+AgYePhOzrkXnHOpzrnUpKSkkw7sFTNjUOdE3vrVGbx0VX8SGkRx55vL+ckTc3lzUTalKtkiIiIiJ+zqq68mOTmZnj17Bvy9AlmuFwCdzay9mUUB44H3qvjcTcBQM4sws0hgKBBS00IqY2YM65rMuzecyf/7RSoNoiK47fVlnDNlHu8u3UxZeWisSS4iIiJSk6688ko+/vjjGnmvgJVr51wpcCPwCb5i/JpzLs3MHjCziwDMrL+ZZQNjgefNLM3/9DeAdcAKYBmwzDk3M1BZaxsz4yfdm/LBTYP4+xWnEhUexs3TlzJyyjw+WL6VcpVsERERkSobMmQICQkJNfJeAb38uXPuQ+DDwx77Q4XbC/BNFzn8eWXAdYHMFgzMjJE9m3FO96Z8uHIrUz5fyw1TF5PSLI5bftKFc3s0JUiX/xYREZE66P6ZaazasqdaX7N7i3juvbBHtb7mydAVGoNAWJgx6pQWfHLLEJ4a34fi0nKu/88iRj3zJbNWbydULmEvIiIiEuwCOnIt1Ss8zBjdpyUX9GrOu0u38NSstVzz8kJ6t2rIb8/uwtAuSRrJFhERkVqrNo0wB4pGroNQRHgYPzu1FbNuG8qff9aLvIJirvzXAi75+zd8lZmnkWwRERERj6hcB7HI8DDG9W/D7NuH8fBPe7Jl134u/3/fMe6Fb/l2fb7X8URERERqhQkTJnD66aeTnp5Oq1at+Mc//hGw99K0kBAQFRHG5ae15Wf9WjFjQRbPzc5k/AvfckbHJtx6dhdS29XM2bEiIiIitdG0adNq7L00ch1CYiLD+b8z2jHvzuHcM6o7Gdv3csnfv+EX//yeJZt2eh1PREREJOSpXIegmMhwrhnUnnl3DmfyeSmsyN7FT//6NVe/tIAV2bu9jiciIiISslSuQ1j9qAiuG9qR+ZNGcMe5XVm0cScXPvsl1/57YbWvMSkiIiIiKtd1Qmx0BDcM78T8ScO59ewufLs+n/Ofns+vX11Exva9XscTERGREBFqK5adyPGoXNch8TGR3HRWZ768cwQ3jejEvIw8zp0yj99MW0JmToHX8URERCSIxcTEkJ+fHzIF2zlHfn4+MTExx/U8C5UPIDU11S1cuNDrGEFlZ2ExL8xfz8tfb6CopIyL+7TkprM60y6xgdfRREREJMiUlJSQnZ1NUVGR11GqTUxMDK1atSIyMvJHj5vZIudcamXPUbkW8goO8MK89fz7mw2UlDnG9PWV7NYJ9b2OJiIiIlLrqFxLleTsLeLvc9bzn+82Ul7uGJvamhtHdKJlo3peRxMRERGpNVSu5bhs213EX+dkMv37LByO8f3bcMPwTjRreHxzjkRERERCkcq1nJDNu/bz3OxMXluQRViYcdmANvx6eEeS41SyRUREpO5SuZaTkrVjH898sZY3F28mMtz4+cC2XDe0I4mx0V5HExEREalxKtdSLTbkFfL0F2t5Z8lmoiN8l1qfOKQDCQ2ivI4mIiIiUmNUrqVarcst4KnP1zJz+RbqR4Zz9aD2/HJQBxrWjzz2k0VERESCnMq1BETG9r089flaPlixlbjoCK4Z3J6rB7UnPkYlW0REREKXyrUE1Oqte3jysww+XbWdRvUjmXbtQLo1j/c6loiIiEhAHK1c6/LnctK6NY/nhV+kMvPGQYSb8bu3V1BeHhq/tImIiIgcD5VrqTa9WjVk8vndWLJpF68vyvI6joiIiEiNU7mWavWzfi0Z0C6BP320hp2FxV7HEREREalRKtdSrcyMBy7uwZ6iUh79ZI3XcURERERqlMq1VLuUZvFcdUY7pi/IYsmmnV7HEREREakxKtcSELec3YXkuGjueXclZTq5UUREROoIlWsJiNjoCO6+oDsrN+/h1e82eh1HREREpEaoXEvAjDqlOYM6JfKXT9LJ3XvA6zgiIiIiAadyLQFjZtw/ugdFJWU88tFqr+OIiIiIBJzKtQRUx6RYJg7pwFuLN/Pd+nyv44iIiIgElMq1BNyNwzvTslE97nl3JSVl5V7HEREREQkYlWsJuHpR4dx7YXcythfw0lcbvI4jIiIiEjAq11Ijzu7elBEpyUz5PINtu4u8jiMiIiISECrXUiPMjPsu7EFpuePBD1Z5HUdEREQkIFSupca0aVKfG4Z34oPlW5m/NtfrOCIiIiLVTuVaatTEIR1o16Q+f3g3jQOlZV7HEREREalWKtdSo2Iiw7l/dE9+yCvkxXnrvY4jIiIiUq1UrqXGDe2SxHk9m/Hs7EyyduzzOo6IiIhItVG5Fk/cM6o7YWbcP1MnN4qIiEjoULkWT7RoVI+bzurM56u3M2v1dq/jiIiIiFQLlWvxzNVntqdzciz3vpfG/mKd3CgiIiLBT+VaPBMVEcYDo3uSvXM/f52T6XUcERERkZOmci2eOr1jEy7u04Ln567nh7xCr+OIiIiInBSVa/Hc7y7oRnREGH94dyXOOa/jiIiIiJwwlWvxXHJcDLee04X5a/P4aOU2r+OIiIiInDCVa6kVfj6wLd2bx/PAzFUUHij1Oo6IiIjICVG5llohIjyMBy/uybY9RTw9a63XcUREREROiMq11Bqntm3MuNTW/OPLH8jYvtfrOCIiIiLHTeVaapVJ56UQGxPB3e/o5EYREREJPirXUqskNIjiznNT+P6HHbyzdLPXcURERESOi8q11Drj+7emd+tGPPzBGnbvL/E6joiIiEiVqVxLrRMWZjw0uif5hQd48rMMr+OIiIiIVJnKtdRKvVo15OcD2/LvbzawcvNur+OIiIiIVInKtdRat53TlYQGUdz9zkrKy3Vyo4iIiNR+AS3XZjbSzNLNLNPM7qpk+xAzW2xmpWZ2yWHb2pjZp2a22sxWmVm7QGaV2qdhvUgmn9eNpVm7eG1hltdxRERERI4pYOXazMKB54DzgO7ABDPrfthum4ArgamVvMS/gb8457oBA4CcQGWV2mtMv5YMaJfAnz9ew87CYq/jiIiIiBxVIEeuBwCZzrn1zrliYDowuuIOzrkNzrnlQHnFx/0lPMI595l/vwLn3L4AZpVaysx44OIe7Ckq5dFP1ngdR0REROSoAlmuWwIV/5af7X+sKroAu8zsLTNbYmZ/8Y+E/4iZTTSzhWa2MDc3txoiS22U0iyeq85ox/QFWSzetNPrOCIiIiJHFMhybZU8VtWz0iKAwcDtQH+gA77pIz9+MedecM6lOudSk5KSTjSnBIFbzu5Cclw097yzkjKd3CgiIiK1VCDLdTbQusL9VsCW43juEv+UklLgHaBfNeeTIBIbHcE9o7qTtmUP//l2o9dxRERERCoVyHK9AOhsZu3NLAoYD7x3HM9tbGYHh6NHAKsCkFGCyAW9mjOoUyKPfZpO7t4DXscRERER+R8BK9f+EecbgU+A1cBrzrk0M3vAzC4CMLP+ZpYNjAWeN7M0/3PL8E0JmWVmK/BNMXkxUFklOJgZ94/uQVFJGY98uNrrOCIiIiL/w5wLjfmrqampbuHChV7HkBrwl0/W8NzsdcyYOJDTOjTxOo6IiIjUMWa2yDmXWtk2XaFRgs6NwzvTslE97nl3JSVl5cd+goiIiEgNUbmWoFMvKpz7LupBxvYC/vXVD17HERERETlE5VqC0tndm3JWSjJTPl/L1t37vY4jIiIiAqhcSxC776IelJU7HnpfJzeKiIhI7aByLUGrdUJ9bhjeiQ9WbGVehq7QKSIiIt5TuZagNnFIB9o1qc+976VxoLTM6zgiIiJSx6lcS1CLiQzn/tE9+SGvkBfnrfc6joiIiNRxKtcS9IZ2SeL8Xs145otMsnbs8zqOiIiI1GEq1xIS7hnVnfAw4/6ZaV5HERERkTpM5VpCQvOG9bj5rM58vjqHz1dt9zqOiIiI1FEq1xIyrh7Uns7Jsdw3M439xTq5UURERGqeyrWEjMjwMB4Y3ZPsnfv565xMr+OIiIhIHaRyLSHl9I5NuLhPC56fu571uQVexxEREZE6RuVaQs7vLuhGdEQY976XhnPO6zgiIiJSh6hcS8hJjovhtnO6MH9tHh+u2OZ1HBEREalDVK4lJF0xsC3dm8fz4PurKDhQ6nUcERERqSNUriUkRYSH8eDFPdm2p4inZ631Oo6IiIjUESrXErJObduYcamt+eeXP5Cxfa/XcURERKQOULmWkDbpvBRiYyK4+52VOrlRREREAk7lWkJaQoMoJo1M4fsfdvD2ks1exxEREZEQp3ItIW9camv6tG7EHz9cze79JV7HERERkRCmci0hLyzMeOjinuwoLOaJT9O9jiMiIiIhTOVa6oSeLRtyxcC2vPLtRlZu3u11HBEREQlRKtdSZ9x2TlcSGkRx9zsrKS/XyY0iIiJS/VSupc5oWC+Syed1Y2nWLl5bmOV1HBEREQlBKtdSp4zp15IB7RL408dr2FFY7HUcERERCTEq11KnmBkPXtyTvUWlPPrxGq/jiIiISIhRuZY6p2uzOK4+sx3TF2SxeNNOr+OIiIhICFG5ljrp5p90oWl8NPe8s5IyndwoIiIi1UTlWuqk2OgI7hnVnbQte/jPtxu9jiMiIiIhQuVa6qwLejVnUKdEHvs0nZy9RV7HERERkRCgci11lpnxwOgeHCgp55EPdXKjiIiInDyVa6nTOiTFMnFIB95esplv1+d7HUdERESCnMq11Hk3DO9Ey0b1+MO7KykpK/c6joiIiAQxlWup8+pFhXPfRT3I2F7Av776wes4IiIiEsRUrkWAs7s35ayUZKZ8vpatu/d7HUdERESClMq1iN99F/WgrNzx0PurvY4iIiIiQUrlWsSvdUJ9bhzeiQ9WbGVeRq7XcURERCQIqVyLVDBxaAfaJzbg3vfSOFBa5nUcERERCTIq1yIVREeEc/9FPfghr5AX5q73Oo6IiIgEGZVrkcMM6ZLE+b2a8ezsTLJ27PM6joiIiAQRlWuRStwzqjvhYcb9M9O8jiIiIiJBROVapBLNG9bjlp905vPVOXy2arvXcURERCRIqFyLHMFVZ7anS9NY7nsvjf3FOrlRREREjk3lWuQIIsPDeGB0Tzbv2s9zszO9jiMiIiJBQOVa5CgGdmjCT/u25IV561mfW+B1HBEREanlVK5FjmHy+SlER4Rx73tpOOe8jiMiIiK1mMq1yDEkx8Vw2zldmL82jw9XbPM6joiIiNRiKtciVXDFwLb0aBHPg++vouBAqddxREREpJZSuRapgojwMB68uCfb9hTx1OcZXscRERGRWkrlWqSK+rVpzPj+rfnnVxtI37bX6zgiIiJSC1W5XJtZSzM7w8yGHPwKZDCR2ujOkSnExURwz7srdXKjiIiI/I+IquxkZn8GxgGrgINX03DAvADlEqmVEhpEMWlkCpPfWsHbSzYzpl8rryOJiIhILVLVkeuLga7OufOdcxf6vy461pPMbKSZpZtZppndVcn2IWa22MxKzeySSrbHm9lmM3u2ijlFAm5camv6tG7EHz9czS71vqsAACAASURBVO79JV7HERERkVqkquV6PRB5PC9sZuHAc8B5QHdggpl1P2y3TcCVwNQjvMyDwNzjeV+RQAsLMx66uCc7Cot54tN0r+OIiIhILVKlaSHAPmCpmc0CDhx80Dl301GeMwDIdM6tBzCz6cBofFNLDj5/g39b+eFPNrNTgabAx0BqFXOK1IieLRvy84FteeXbjYxNbU3Plg29jiQiIiK1QFVHrt/DN4r8NbCowtfRtASyKtzP9j92TGYWBjwO3FHFfCI17tZzupLQIJq731lJeblObhQREZEqlmvn3MvANP5bqqf6Hzsaq+ylqpjr18CHzrmso+1kZhPNbKGZLczNza3iS4tUj4b1Ivnd+SkszdrFjIVH/VEVERGROqJK5drMhgFr8c2h/iuQUYWl+LKB1hXutwK2VDHX6cCNZrYBeAz4hZn96fCdnHMvOOdSnXOpSUlJVXxpkerz074tGdA+gT9/vIYdhcVexxERERGPVXVayOPAOc65oc65IcC5wJPHeM4CoLOZtTezKGA8vuklx+Scu9w518Y51w64Hfi3c+5/VhsR8ZqZ8eDonuwtKuXRj9d4HUdEREQ8VtVyHemcO7QsgnMug2OsHuKcKwVuBD4BVgOvOefSzOwBM7sIwMz6m1k2MBZ43szSTuQgRLzUtVkc1wxqz/QFWSzetNPrOCIiIuIhq8pV5szsn/jmS7/if+hyIMI5d1UAsx2X1NRUt3DhQq9jSB1VeKCUsx6fS0KDKN678Uwiwqt88VMREREJMma2yDlX6Wp2VW0AvwLSgJuAm/Etp3d99cQTCX4NoiO4Z1R3Vm3dw3++3eh1HBEREfFIlda5ds4dAJ7wf4lIJc7v1YzBnRN5/NMMzj+lOclxMV5HEhERkRp21JFrM3vN/98VZrb88K+aiSgSHMyM+y/qwYHSch75UCc3ioiI1EXHGrm+2f/fUYEOIhIKOiTFMnFIB56dncm4/q0Z2KGJ15FERESkBh115No5t9V/Mw/Ics5tBKKB3lR9zWqROuWG4Z1o1bge97yzkpKycq/jiIiISA2q6gmN84AYM2sJzAKuAl4KVCiRYFYvKpz7LuzB2pwC/vnlD17HERERkRpU1XJtzrl9wBjgGefcT4HugYslEtx+0r0pP+mWzJOfZ7B2+16v44iIiEgNqXK5NrPT8a1v/YH/sSqtNCJSV/3xp71oEBXBb6YtoaikzOs4IiIiUgOqWq5vASYDb/uvstgBmB24WCLBLzk+hscv7c2abXt56INVXscRERGRGlDVda7nAnMr3F+P74IyInIUw7omM3FIB16Yt54zOyZyXq/mXkcSERGRADpquTazKc65W8xsJr7Ln/+Ic+6igCUTCRG3n9OV79bnc+eby+nZsiGtE+p7HUlEREQC5Fgj16/4//tYoIOIhKqoiDCemdCPC56ez83TlzDjutOJDK/qjCwREREJJsda53qR/+ZCYL5zbq5/isiXwIJAhxMJFW2a1OePY3qxeNMupnye4XUcERERCZCqDp/NAir+Lbse8Hn1xxEJXRf2bsH4/q3565x1fLk2z+s4IiIiEgBVLdcxzrmCg3f8tzVxVOQ43XthDzomxfLb15aSu/eA13FERESkmlW1XBeaWb+Dd8zsVGB/YCKJhK56UeE8e1lf9uwv4bbXl1Fe/j/nCYuIiEgQO551rl83s/lmNh+YAdwYuFgioSulWTz3jOrOvIxcXpy/3us4IiIiUo2qus71AjNLAboCBqxxzpUENJlICLv8tDZ8lZnHXz5JZ0D7BPq2aex1JBEREakGVRq5NrP6wCTgZufcCqCdmY0KaDKREGZm/GnMKTSNj+Gm6UvYU6TfVUVEREJBVaeF/AsoBk73388GHgpIIpE6omH9SJ6e0Jctu4qY/NYKnNP8axERkWBX1XLd0Tn3KFAC4Jzbj296iIichFPbNubWs7vwwfKtzFiQ5XUcEREROUlVLdfFZlYP/yXQzawjoHXERKrBr4Z2ZFCnRO6bmUbG9r1exxEREZGTUNVyfS/wMdDazF7Fd1GZOwOWSqQOCQsznhjXm9joCG6cupiikjKvI4mIiMgJOma5NjMD1gBjgCuBaUCqc25OQJOJ1CHJcTE8fmkfMrYX8OD7q7yOIyIiIifomOXa+c6yesc5l++c+8A5975zTtduFqlmQ7skcd3QDrz63SY+XLHV6zgiIiJyAqo6LeRbM+sf0CQiwu3ndKVP60ZMenM5WTv2eR1HREREjlNVy/VwfAV7nZktN7MVZrY8kMFE6qLI8DCemdAXHNw0fQklZeVeRxIREZHjUNVyfR7QARgBXAiM8v9XRKpZ64T6/HFML5Zs2sUTn2V4HUdERESOw1Evf25mMcD1QCdgBfAP51xpTQQTqcsu7N2Cr9fl8bc56zijYxMGd07yOpKIiIhUwbFGrl8GUvEV6/OAxwOeSEQA+MOoHnROjuW3M5aRu1fLyouIiASDY5Xr7s65K5xzzwOXAINrIJOIAPWiwnn2sn7sLSrh1teWUl6uy6OLiIjUdscq1yUHb2g6iEjN69osjnsv7MH8tXm8MH+913FERETkGI465xrobWZ7/LcNqOe/b/iWwI4PaDoRYcKA1nyVmcdjn6QzoH0C/do09jqSiIiIHMFRR66dc+HOuXj/V5xzLqLCbRVrkRpgZvxxTC+axsdw07Ql7N5fcuwniYiIiCequhSfiHioYb1InrmsL1t3F/G7t1bgu3CqiIiI1DYq1yJBol+bxtx+Tlc+WLGV6QuyvI4jIiIilVC5Fgki1w3pwODOidz3XhoZ2/d6HUdEREQOo3ItEkTCwozHL+1NXEwEN05dzP7iMq8jiYiISAUq1yJBJjkuhicu7UPG9gIeeH+V13FERESkApVrkSA0pEsS1w/tyLTvN/H+8i1exxERERE/lWuRIHXbOV3o07oRk99cQdaOfV7HEREREVSuRYJWZHgYz0zoCwa/mbaEkrJyryOJiIjUeSrXIkGsdUJ9/jTmFJZm7eLxTzO8jiMiIlLnqVyLBLkLTmnOhAFt+PvcdczLyPU6joiISJ2mci0SAv4wqjtdmsZy62tLydlb5HUcERGROkvlWiQE1IsK59nL+lFwoJRbZyyjvFyXRxcREfGCyrVIiOjSNI57L+zBl5l5PD9vvddxRERE6iSVa5EQMr5/ay44pTmPfZrOoo07vY4jIiJS56hci4QQM+ORMb1o3jCGm6YtYff+Eq8jiYiI1Ckq1yIhJj4mkmcm9GX7niLuenM5zmn+tYiISE1RuRYJQX3bNOb2c7vy0cptTP1+k9dxRERE6gyVa5EQNXFwBwZ3TuSBmatI37bX6zgiIiJ1gsq1SIgKCzOeuLQPcTGR3Dh1MfuLy7yOJCIiEvJUrkVCWFJcNFPG9SEzt4AH3k/zOo6IiEjIC2i5NrORZpZuZplmdlcl24eY2WIzKzWzSyo83sfMvjGzNDNbbmbjAplTJJQN6pzI9UM7Mu37LGYu2+J1HBERkZAWsHJtZuHAc8B5QHdggpl1P2y3TcCVwNTDHt8H/MI51wMYCUwxs0aByioS6m49uwt92zTid2+tYFP+Pq/jiIiIhKxAjlwPADKdc+udc8XAdGB0xR2ccxucc8uB8sMez3DOrfXf3gLkAEkBzCoS0iLDw3h6fF8w+M30JRSXlh/7SSIiInLcAlmuWwJZFe5n+x87LmY2AIgC1lWybaKZLTSzhbm5uSccVKQuaJ1Qnz//7BSWZe3i8U/TvY4jIiISkgJZrq2Sx47rahZm1hx4BbjKOfc/Q23OuRecc6nOudSkJA1sixzL+b2ac/lpbXh+3nrmZugXUhERkeoWyHKdDbSucL8VUOWzqcwsHvgAuNs59201ZxOps+4Z1Z2uTeO4dcZScvYUeR1HREQkpASyXC8AOptZezOLAsYD71Xlif793wb+7Zx7PYAZReqcmMhwnr2sL4XFpfz2taWUl+vy6CIiItUlYOXaOVcK3Ah8AqwGXnPOpZnZA2Z2EYCZ9TezbGAs8LyZHVyI91JgCHClmS31f/UJVFaRuqZz0zjuu7AHX2Xm87e5/3M6g4iIiJwgcy40Rq1SU1PdwoULvY4hEjScc/xm2hI+WrmN164byKltE7yOJCIiEhTMbJFzLrWybbpCo0gdZWb8cUwvWjSK4aZpS9m9r8TrSCIiIkFP5VqkDouPieSZCf3YvqeIu95aTqj8JUtERMQrKtcidVyf1o2449yufLRyG69+t8nrOCIiIkFN5VpEuHZwB4Z0SeKB91exeuser+OIiIgELZVrESEszHji0t40rBfJb6YtYV9xqdeRREREgpLKtYgAkBgbzZOX9mFdbgH3v7fK6zgiIiJBSeVaRA4Z1DmRXw/ryIyFWby3rMoXVBURERE/lWsR+ZFbftKFU9s25ndvrWBT/j6v44iIiAQVlWsR+ZHI8DCeGt+HMIPfTFtMcWm515FERESChsq1iPyPVo3r8+efncKy7N089mm613FERESChsq1iFTqvF7NuWJgG16Yt57Z6TlexxEREQkKKtcickR3X9CdlGZx3P7aMnL2FHkdR0REpNZTuRaRI4qJDOfZy/qyr7iMW2Yspaxcl0cXERE5GpVrETmqTslx3H9RD75el8/f567zOo6IiEitpnItIsc0NrUVF/ZuwROfZbBwww6v44iIiNRaKtcickxmxsM/7UnLRvW4efpSdu0r9jqSiIhIraRyLSJVEh8TyTMT+rJ9TxGT3lyOc5p/LSIicjiVaxGpst6tGzFpZAqfpG3nP99u9DqOiIhIraNyLSLH5ZpB7RnWNYkHP1jN6q17vI4jIiJSq6hci8hxCQszHhvbm4b1Irlx6mL2FZd6HUlERKTWULkWkeOWGBvNlHF9WJ9XyH3vpXkdR0REpNZQuRaRE3Jmp0RuGNaJ1xZm8+7SzV7HERERqRVUrkXkhN3yk86ktm3M799eyYa8Qq/jiIiIeE7lWkROWER4GE9N6EuYwU3Tl1BcWu51JBEREU+pXIvISWnZqB6PXtKb5dm7+csna7yOIyIi4imVaxE5aSN7NuPnA9vy4vwfmL0mx+s4IiIinlG5FpFq8fsLupHSLI7bXl/G9j1FXscRERHxhMq1iFSLmMhwnr2sL/uLy7hl+lLKynV5dBERqXtUrkWk2nRKjuP+0T34Zn0+f52d6XUcERGRGqdyLSLVauyprRjdpwVTZq1lwYYdXscRERGpUSrXIlKtzIyHLu5Jq8b1uHnaEnbtK/Y6koiISI1RuRaRahcXE8kzE/qSW3CAO99YjnOafy0iInWDyrWIBMQprRoxaWQKn67azivfbvQ6joiISI1QuRaRgLn6zPYM75rEQ++vJm3Lbq/jiIiIBJzKtYgETFiY8djY3jSqH8lvpi1hX3Gp15FEREQCSuVaRAKqSWw0U8b34Ye8Qq74f9+xKX+f15FEREQCRuVaRALujI6JPD2+L2tzCjjvqXm8tiBLJzmKiEhIUrkWkRpxYe8WfHzLEHq1asidby7nulcWkV9wwOtYIiIi1UrlWkRqTMtG9Zj6y4H87vwU5qTncu6U+cxek+N1LBERkWqjci0iNSoszJg4pCPv3ngmTRpEcdVLC7j7nRU62VFEREKCyrWIeKJb83jevfFMfjmoPf/5dhOjnv6SZVm7vI4lIiJyUlSuRcQzMZHh3D2qO1N/eRr7S8oY87eveXrWWkrLyr2OJiIickJUrkXEc2d0SuTjm4cw6pTmPPFZBmOf/4aN+YVexxIRETluKtciUis0rB/JU+P78vSEvqzLKeC8p+Yz7ftNWrJPRESCisq1iNQqF/mX7OvTuhGT31rBtf9eRJ6W7BMRkSChci0itU6LRvX4zzWncfcF3Zi3NpeRU+Yxa/V2r2OJiIgck8q1iNRKYWHGLwd3YOaNg0iMjeaalxcy+S0t2SciIrWbyrWI1Gpdm8Xx7o1nct2QDkxfsInzn5rPkk07vY4lIiJSKZVrEan1oiPCmXx+N6ZdO5CSMsclf/+GJz/LoERL9omISC2jci0iQWNghyZ8dMtgRvduwVOz1nLJ37/hhzwt2SciIrWHyrWIBJX4mEieGNeH5y7rx4a8Qs5/aj6vfrdRS/aJiEitoHItIkHpglOa88ktQ0ht15jfv72Sa15eSO5eLdknIiLeUrkWkaDVrGEML181gHsv7M5XmXmcO2Uen6Zt8zqWiIjUYQEt12Y20szSzSzTzO6qZPsQM1tsZqVmdslh2/7PzNb6v/4vkDlFJHiFhRlXndme938ziGbxMUx8ZRGT3lhO4QEt2SciIjUvYOXazMKB54DzgO7ABDPrfthum4ArgamHPTcBuBc4DRgA3GtmjQOVVUSCX+emcbxzw5n8alhHXluUxXlPzWfRRi3ZJyKhoaikjM279lOggYNaLyKArz0AyHTOrQcws+nAaGDVwR2ccxv82w5fT+tc4DPn3A7/9s+AkcC0AOYVkSAXFRHGpJEpDO+azK2vLWXs37/mhuGduOmszkSGaxaciNQeJWXl7CwsJq+gmB2FxeQXHiCvoJj8ggPs8D+eX+i7nV9QfKhUR4QZqe0aM7xrMsNTkumcHIuZeXw0UlEgy3VLIKvC/Wx8I9En+tyW1ZRLRELcgPYJfHTzYO6fuYpnvshkbkYuT47rQ8ekWK+jiUiIKi937NpfQn7Bgf8pzDsKD5Bf4CvJef7CvGtfSaWvEx5mJDSIokmDKBJjo2nduD5NYn23ExpEsTF/H3PSc3jkozU88tEaWjSMYVhKMsO7JnNGxyY0iA5ktZOqCOR3oLJfo6q6VlaVnmtmE4GJAG3atKl6MhEJeXExkTw2tjdnpSQz+e0VXPD0fH5/fjeuGNhWozwickzOOfYeKPWX4gPk+0eQD90u9N+uMMJcXknLMYPG9aMOFeZuzeJ9t2OjaBIbTWID/7bYaBJjo4iPiSQs7Oj/Rt11Xgpbd+9nTnouc9JzeHfJZqZ+t4mo8DAGtE9gWNckhnVNpmNSA/175wEL1NqwZnY6cJ9z7lz//ckAzrlHKtn3JeB959wb/vsTgGHOuev8958H5jjnjjgtJDU11S1cuLDaj0NEgl/OniLueGM5czNyGdY1iUd/dgrJ8TFexxKRGrav2F+WC49dmHcUFlN8hKvAxsVEHBpJbuIvxk0OL8yxUTRpEE3j+pFEBHhaWnFpOQs37GBORi6z1+SwNqcAgNYJ9RjWJZnhKUmc3iGRelHhAc1Rl5jZIudcaqXbAliuI4AM4CxgM7AAuMw5l1bJvi/x43KdACwC+vl3WQycenAOdmVUrkXkaJxzvPLtRh7+YDX1o8J5ZMwpjOzZzOtYInISikvL/fOTDxwqxofmK1dSmPeXlFX6OjGRYSTGRv+3JFdSmA/eTmgQRXRE7S6p2Tv3HRrV/iozn/0lZURFhDGwQxOGd01ieNdk2iU28DpmUPOkXPvf+HxgChAO/NM597CZPQAsdM69Z2b9gbeBxkARsM0518P/3KuB3/lf6mHn3L+O9l4q1yJSFZk5Bfx2xlJWbN7N2FNbce9FPYjVHEWRWsc5R9qWPSzauJO8gh+f7JfvL9R7iypfOSMy3GjSIPpQGU48VI4rL8z1o0L334CikjIWbNjB7DW5zMnIYX1uIQDtmtRnmP+kyNPaJxATWbt/YahtPCvXNUnlWkSqqri0nKdnreWvczJp2bgeT17ah9R2CV7HEqnzCg+U8mVmHrPX5PDFmhxy/FddDTP8UzAqL8y++/7CHBtFXHSE5hofwcb8wkOj2l+vy+dAaTkxkWGc0TGRYf5R7dYJ9b2OWeupXIuIVGLRxh38dsYysnfu41fDOnLzWV2IitCSfSI1aVP+Pr5Ys51Za3L4bv0OisvKiYuOYEiXJIanJDOoUyJJcdGEH+MkPzl+RSVlfLs+nznpucxOz2Fj/j4AOiY18I1qd02mf/vGtX4ajBdUrkVEjqDgQCkPzEzjtYXZ9GwZz5RxfeiUHOd1LJGQVVJWzqKNO/nCPzqd6T/5rkNSA0Z0TWZEt2T6t0vQ2vQe+CGvkNlrcpidnsN3P+yguLSc+lHhnNExkeEpvhVIWjaq53XMWkHlWkTkGD5J28bkt1ZQeKCUyeel8H9ntNOflUWqyY7CYuak+8r03Ixc9haVEhlunNa+CSNSkhmRohPsapt9xaV8sy6f2ek5zF6Ty+Zd+wHo0jSW4V2TGdo1idS2CXX2r30q1yIiVZCzt4hJbyxndnougzsn8tjY3jTVkn0ix805x+qte5mdnsOs1dtZkrUL5yAxNpoRKUmMSElmUOcknUwcJJxzrMstODR95PsfdlBS5oiNjmBQp8RD62o3a1h3/r1UuRYRqSLnHK9+t4mHPlhFTGQ4f/xpL87v1dzrWCK13v7iMr5el8esNTnMXpPD1t1FAJzSqiHDuyZzVrdkerZoeMwLpEjtV3CglK8z85jtPzHy4Pe6W/P4QydF9mvTKODre3tJ5VpE5Ditz/Ut2bcsezdj+rXkvot6EB8T6XUskVole+e+Qyt7HFx5okFUOIM6J3JWSlOGdU3SBZtCnHOOjO0F/ukjOSzauJPSckdcTARDOicxrGsSQ7smkRwXWj8HKtciIiegpKycZ77I5LnZmTSLj+HJcX0Y0F5L9kndVVpWzpKsXb6TEVfnkL59LwBtm9Q/NHd6QPsErS5Rh+0pKuGrtXnMTs9hTnruoeUUe7aMZ3jXZIZ1TaJP68ZBv/qLyrWIyElYvGknv52xlE079nHdkI789uzOKg9SZ+zaV8zcjNxDJyPu2ldCRJjRv12Cr1B3S6ZDYgOdACz/wznHqq17Dq2rvWjjTsodNKof+d9R7S5JNImN9jrqcVO5FhE5SYUHSnnog1VM+z6Lbs3jeWp8H7o01ZJ9EnoO/pnft1Te9kOFKKFBFMO6JnFWSlMGd0nUNCk5brv3lTBvbS5z0nOZm5FDXkExZnBKq0YM869rfkrL4JiXr3ItIlJNPlu1nbveXM7eA6XcNTKFK89oFxT/RyByNEUlZXyzPp8vVvvmTx9cdq1783jO6ua7RHbvVo2C/k/5UnuUl/subz873beu9lL/ijJNGkQxpItvVHtI5yQaN4jyOmqlVK5FRKpRXsEB7npzOZ+vzmFQJ9+SfXVpCSoJDVt372f2mly+WLOdLzPzKCopp15kOGd2SmRESjLDU5Jo3lAXDJGasaOwmPlrc5m9Jod5a/PYUVhMmEGf1o0Y3tX3C1735vG1ZjBD5VpEpJo555i+IIsHZq4iKiKMhy7uyYW9W3gdS+SIysody7J3HRqdXrV1DwCtGtc7dDLiwA5NiInU+QTirbJyx/LsXcxOz2Vueg7LsncDvnXSfWtqJzG4cxIN63k3NUnlWkQkQH7IK+S3M5ayNGsXF/dpwf2je3r6D75IRbv3lzB/re9kxDnpuewoLCY8zDi1TWNGdPMV6s7JsToZUWq1vIIDzMvIZXZ6LvMyctm9v+TQz/HNP+nMmZ0SazzT0cq1Lo0kInIS2ic24I3rT+e52et4+ou1fP/DDh6/tA+nd2zidTSpg3xX0itk9pocZq3ZzsINvjWHG9WPPHTC2NAuSTSqXzvnsYpUJjE2mjH9WjGmXytKy8pZlr2L2WtymZORQ20cI9bItYhINVmatYvfzljKhvxCrh3cgdvO6aIl+yTgDpSW8f0PO5i12ndi2Mb8fQCkNItjeEoyZ6Uk07dN8K8rLFKbaFqIiEgN2VdcysMfrObV7zaR0iyOKeP7kNIs3utYEmJy9hQxO903d3r+2jz2FZcRHRHGGR2bMKJbU0akJNOykU5GFAkUlWsRkRr2xZrt3PnGCvbsL+HOkV25+sz2teYsdwk+5eWOFZt3+9ee/v/t3WuMXPV5x/Hvs7u2195ZX1jvGtuA78bYRAYDiQsttIDUVG0ClRolNKma9k1VNSm9RklV9aK8qFBplKpp0kZp+wZUSClpeolIk5SgUrVuwk0mdupdBwdsnN2NAXsHg72Xpy9mPIwvi3w5+Jxdvh9ptbPnHM15Rns089N/nv//jLDzQGOC1/JF3a3JiDeuW8r8uX5TIl0MhmtJKsGh+jE+/vBOvrZrmBvX9XHv+7aywtFEnaX6sQkeHxxttnuM8sP6MSJg2xVLWoF606W9TkaUSmC4lqSSZCZf/PYL/PG/7KKrI/jknVdzxzUryy5LFXT46Di7Dh7h2QOHeWzPKDueO8T4ZLKwu4ubN/Zz21UD3LJxgEsqelMN6e3E1UIkqSQRwftvuILta/v4rS8+w90PPM03do/wyTuuZtECl+x7O8pM9r/8GrsOHmHXi0dav0/cFRFg/UCNX75pDT+xaYDrVi1hTmdHiRVLOheOXEvSRTIxOcVfPbaXT399kMUL5vLONUtYP9DLhoEaG5bVWLO0x9VFZpnjE1MMjoydFKJ3HTzC2OsTAETA2qU9bF6xiM3LF7J5xUKuWt7LQK93/JSqzJFrSaqArs4OPnLrBm7e2M9nH93Ldw+O8cizP2CqOcbREbCqr4f1A7VW4N4w0Mu6/poT1WaAE20d7SF6aGSM8cnGP3j+nE42Le/lvVtXsHnFQjYvX8iVl/ayYK4fxdJs4si1JJXo9fFJ9h16lcHhOoMjdYZGxhgcrrPv0KutUBYBKxfPbwbu3lb4Xj9Qo7fb1pKL7WzaOvp757VGok/8Xt3X41rT0izhyLUkVVT3nE42XbrwtLWwxyen+P6ho62wPTjS+PmvvYc4PjHVOm75om7WN4P2hoHe5mh3zTvwFeRs2zq2rVrCh7avsq1DkiPXkjSTTE4l+18+2ha4xxgaqTM0Uufo8cnWcUtr81g/0NMK3CfC99LaXJdum8bZtnW0j0jb1iG9PTlyLUmzRGdHsKqvh1V9Pdy+eVlr+9RUcvDI6wwON8J2I3yP8U9PH2iNsgIsXjCn1VLSPpny0oXdb5vQnZkceOW100aj9798YsQvMwAAB31JREFUelvHj1/Zb1uHpHPiyLUkzWKZycjYMQaHm/3czfaSweExXj463jquNq/rpF7uE5MpVy6eP6PvLHl8YoqhkXpbiD7MrhePcMTVOiRdAG8iI0k6zaH6sVbY3ttsMRkcrjMydqx1TPecjlZLyRu93TWuuGQBXRVbe/nwa+PsPmWS4aBtHZLeAraFSJJO01ebR19tHtvX9p20/fDRcYZGx9pWMKnzv8+9xJeeOtA6Zm5nB2v7e04K3huW1Vjd18Pcrrc2dJ9LW8cttnVIusgcuZYknZX6sYnmCHdzIuVwnaHROs+/dJQTHyWdHcHqvgUnTaRcP1BjXX+N7jnnvla3bR2SqsiRa0nSBavN62Lr5YvZevnik7a/Pj7J3tH6SRMp94yM8bXdw0xOvbFW9xWXLGj2dPe2Taqs0TOv8VF0tm0d7/EmLJIqzHckSdIF6Z7TyZYVi9iyYtFJ249PTLXdIKcxmXJouM5je0ZbgRkaN8iJwLYOSbOC4VqS9JaY29XBxmW9bFzWCyxvbZ+YnOL5l462+rn3DI8xlfDBd3kTFkkzn+FaknRRdXV2sLa/xtr+Gj+5pexqJKlY1VpHSZIkSZrBDNeSJElSQQzXkiRJUkEM15IkSVJBDNeSJElSQQzXkiRJUkEM15IkSVJBDNeSJElSQQzXkiRJUkEM15IkSVJBDNeSJElSQQzXkiRJUkEM15IkSVJBIjPLrqEQETEKfL+k0y8FfljSuVVtXhuajteG3ozXh6bjtVENqzKz/0w7Zk24LlNEfDszry+7DlWP14am47WhN+P1oel4bVSfbSGSJElSQQzXkiRJUkEM18X4fNkFqLK8NjQdrw29Ga8PTcdro+LsuZYkSZIK4si1JEmSVBDD9QWIiHdHxP9FxFBEfLzselQdEXF5RDwaEbsj4jsRcXfZNalaIqIzIp6KiH8tuxZVR0QsjoiHIuK7zfePHym7JlVDRPxm8/Pk2Yj4+4joLrsmnZnh+jxFRCfwl8BPAZuBuyJic7lVqUImgN/OzKuA7cCveX3oFHcDu8suQpXz58AjmbkJ2IrXiICIWAn8OnB9Zl4NdAIfKLcqTcdwff7eCQxl5vcy8zjwAHBHyTWpIjLzYGY+2Xw8RuMDcmW5VakqIuIy4KeBL5Rdi6ojIhYCNwN/A5CZxzPzlXKrUoV0AfMjogtYALxYcj2ahuH6/K0EXmj7ez+GJ51BRKwGrgV2lFuJKuTTwMeAqbILUaWsBUaBv2u2DH0hInrKLkrly8wDwL3A88BB4HBm/nu5VWk6huvzF2fY5tIrOklE1IB/BH4jM4+UXY/KFxE/A4xk5hNl16LK6QK2AZ/LzGuBVwHn84iIWELj2/E1wAqgJyI+VG5Vmo7h+vztBy5v+/sy/IpGbSJiDo1gfX9mPlx2PaqMm4D3RsQ+Gu1kt0bEfeWWpIrYD+zPzBPfcj1EI2xLtwPPZeZoZo4DDwM3llyTpmG4Pn/fAjZExJqImEtjYsE/l1yTKiIigkbf5O7M/FTZ9ag6MvMTmXlZZq6m8b7xH5npCJTIzB8AL0TElc1NtwG7SixJ1fE8sD0iFjQ/X27Dya6V1VV2ATNVZk5ExEeAr9KYtfu3mfmdkstSddwE/AKwMyKebm77vcz8Sok1Saq+jwL3Nwdtvgf8Usn1qAIyc0dEPAQ8SWM1qqfwTo2V5R0aJUmSpILYFiJJkiQVxHAtSZIkFcRwLUmSJBXEcC1JkiQVxHAtSZIkFcRwLUkzWER8MyKuL7uOEyLiwxHxmbLrkKSyGK4lSZKkghiuJWkGiIieiPi3iHgmIp6NiPef4Zi7ImJnc/89bdvrEfFnEfFkRHwjIvqb29dFxCMR8URE/GdEbDrl+ToiYl9ELG7bNhQRyyLiPRGxIyKeioivR8Syt/L1S9JMYbiWpJnh3cCLmbk1M68GHmnfGRErgHuAW4FrgBsi4s7m7h7gyczcBjwG/GFz++eBj2bmdcDvAJ9tf87MnAK+DPxs8xzvAvZl5jDwOLA9M68FHgA+VvDrlaQZyXAtSTPDTuD2iLgnIn4sMw+fsv8G4JuZOZqZE8D9wM3NfVPAg83H9wE/GhE14EbgHyLiaeCvgeVnOO+DwIlR8g+0Pc9lwFcjYifwu8CWC36FkjQLGK4laQbIzD3AdTRC9p9ExB+cckicy9PReP9/JTOvafu56gzH/jewvtlKcifwcHP7XwCfycx3AL8CdJ/D+SVp1jJcS9IM0Gz7OJqZ9wH3AttOOWQHcEtELI2ITuAuGi0g0Hiv/7nm458HHs/MI8BzEfG+5vNHRGw99byZmcCXgE8BuzPzUHPXIuBA8/EvFvEaJWk26Cq7AEnSWXkH8KcRMQWMA7/avjMzD0bEJ4BHaYxifyUzv9zc/SqwJSKeAA7zRpvHB4HPRcTvA3No9E4/c4ZzPwh8C/hw27Y/otFScgD4H2DNhb5ASZoNojEoIUmarSKinpm1suuQpLcD20IkSZKkgjhyLUmSJBXEkWtJkiSpIIZrSZIkqSCGa0mSJKkghmtJkiSpIIZrSZIkqSCGa0mSJKkg/w+NApuFvYkX8gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# seeing for which slopes we achieved better results\n",
    "# defining differen environments for different slopes\n",
    "slope_vals = [1]\n",
    "train_metrics = pd.DataFrame([])\n",
    "test_metrics = pd.DataFrame([])\n",
    "\n",
    "for slope_val in slope_vals:\n",
    "    path_strategic = f\"./tests/slope_test_{slope_val}/strategic\"\n",
    "\n",
    "    # reading metrics\n",
    "    train_metric = pd.read_csv(path_strategic + '/train_metrics.csv')\n",
    "    train_metric[\"slope_val\"] = slope_val\n",
    "    train_metrics = pd.concat([train_metrics, train_metric])\n",
    "\n",
    "    test_metric = pd.read_csv(path_strategic + '/test_metrics.csv')\n",
    "    test_metric[\"slope_val\"] = slope_val\n",
    "    test_metrics = pd.concat([test_metrics, test_metric])\n",
    "\n",
    "print(test_metrics[\"burden\"])\n",
    "# test_metrics[\"burden\"] = \n",
    "\n",
    "\n",
    "# TODO: results are not good (in precision, recall and ndcg), maybe there is a problem with the model. implement naive approach (strategic data and non-strategic model) and compare\n",
    "# plotting\n",
    "(\n",
    "    test_metrics\n",
    "    .pivot(\n",
    "        index='epoch num',\n",
    "        columns='slope_val',\n",
    "        values='burden',\n",
    "    )\n",
    "    .plot.line(\n",
    "        title='precision over different slope vals',\n",
    "        xlabel='slope val',\n",
    "        ylabel='Precision',\n",
    "        figsize=(12,6),\n",
    "    )\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: Burden vs. Accuracy for different k values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining 3 differen environments for 3 different models: low k, k, and high k\n",
    "k_vals = [??????]\n",
    "\n",
    "\n",
    "for k in k_vals:\n",
    "    # training with different slopes\n",
    "    env_params = {'noisyscale' : 0.01,\n",
    "                'n_features' : 5,\n",
    "                'k' : k,\n",
    "                'k_tag' : k,\n",
    "                'n_users': 200,\n",
    "                'slope_low' : ???????,\n",
    "                'slope_high' : ???????,\n",
    "                'acp_reward' : 0.6,\n",
    "                'funcs' : funcs,\n",
    "                'funcs_batch' : funcs_batch,\n",
    "                'scale' : 1}\n",
    "    \n",
    "    rank_env = RankingEnv(**env_params)\n",
    "    model = MyStrategicModel(batch_size=env_params['n_users'], env=rank_env, strategic=True)\n",
    "    \n",
    "    # generate train and test sets\n",
    "    X_train, R_train, y_train = rank_env.generate_dataset()\n",
    "    X_test, R_test, y_test = rank_env.generate_dataset()\n",
    "\n",
    "    path_strategic = f\"./tests/k_test_{k}/strategic\"\n",
    "    epochs = 10\n",
    "    batch_size = env_params['n_users']\n",
    "    total = []\n",
    "    ccp = []\n",
    "\n",
    "    print('now training strategic model')\n",
    "    strategic_train_metrics, strategic_test_metrics = model.fit(path_strategic, X_train, R_train, X_test, R_test,\n",
    "                        opt=torch.optim.Adam, opt_kwargs={\"lr\": (1e-1)},\n",
    "                        batch_size=batch_size, epochs=epochs, verbose=True,\n",
    "                    comment=\"batched\")\n",
    "\n",
    "    total_time = model.total_time\n",
    "    ccp_time = model.ccp_time\n",
    "    total.append(total_time)\n",
    "    ccp.append(ccp_time)\n",
    "\n",
    "    # saving baseline\n",
    "    pd.DataFrame(np.array(total)).to_csv(path_strategic + '/total_timing_results.csv')\n",
    "    pd.DataFrame(np.array(ccp)).to_csv(path_strategic + '/ccp_timing_results.csv')\n",
    "    pd.DataFrame(strategic_train_metrics).to_csv(path_strategic + '/train_metrics.csv')\n",
    "    pd.DataFrame(strategic_test_metrics).to_csv(path_strategic + '/test_metrics.csv')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3: Burden vs. Accuracy for different k tag values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
